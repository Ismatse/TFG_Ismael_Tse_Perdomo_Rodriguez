{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1w95xFSJ7i2-4v-JR8M07Sh2ewWoZOBBq","authorship_tag":"ABX9TyOAi7PZ6B/OcTftut+jqeLC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"CLXTw4SVjMd5"},"outputs":[],"source":["import keras"]},{"cell_type":"code","source":["model = keras.applications.ResNet50(\n","    include_top=True,\n","    weights=None,\n","    input_tensor=None,\n","    input_shape=(256,512,3),\n","    pooling=None,\n","    classes=1000,\n","    classifier_activation=\"softmax\",\n",")"],"metadata":{"id":"Ni9DapMij1tc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nAWTwqnVj-yN","executionInfo":{"status":"ok","timestamp":1712510288019,"user_tz":-120,"elapsed":3687,"user":{"displayName":"Ismael","userId":"03967480790510634870"}},"outputId":"ca3e02d5-272e-4bff-adce-0bd53ea3ae2d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"resnet50\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_2 (InputLayer)        [(None, 256, 512, 3)]        0         []                            \n","                                                                                                  \n"," conv1_pad (ZeroPadding2D)   (None, 262, 518, 3)          0         ['input_2[0][0]']             \n","                                                                                                  \n"," conv1_conv (Conv2D)         (None, 128, 256, 64)         9472      ['conv1_pad[0][0]']           \n","                                                                                                  \n"," conv1_bn (BatchNormalizati  (None, 128, 256, 64)         256       ['conv1_conv[0][0]']          \n"," on)                                                                                              \n","                                                                                                  \n"," conv1_relu (Activation)     (None, 128, 256, 64)         0         ['conv1_bn[0][0]']            \n","                                                                                                  \n"," pool1_pad (ZeroPadding2D)   (None, 130, 258, 64)         0         ['conv1_relu[0][0]']          \n","                                                                                                  \n"," pool1_pool (MaxPooling2D)   (None, 64, 128, 64)          0         ['pool1_pad[0][0]']           \n","                                                                                                  \n"," conv2_block1_1_conv (Conv2  (None, 64, 128, 64)          4160      ['pool1_pool[0][0]']          \n"," D)                                                                                               \n","                                                                                                  \n"," conv2_block1_1_bn (BatchNo  (None, 64, 128, 64)          256       ['conv2_block1_1_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv2_block1_1_relu (Activ  (None, 64, 128, 64)          0         ['conv2_block1_1_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv2_block1_2_conv (Conv2  (None, 64, 128, 64)          36928     ['conv2_block1_1_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv2_block1_2_bn (BatchNo  (None, 64, 128, 64)          256       ['conv2_block1_2_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv2_block1_2_relu (Activ  (None, 64, 128, 64)          0         ['conv2_block1_2_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv2_block1_0_conv (Conv2  (None, 64, 128, 256)         16640     ['pool1_pool[0][0]']          \n"," D)                                                                                               \n","                                                                                                  \n"," conv2_block1_3_conv (Conv2  (None, 64, 128, 256)         16640     ['conv2_block1_2_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv2_block1_0_bn (BatchNo  (None, 64, 128, 256)         1024      ['conv2_block1_0_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv2_block1_3_bn (BatchNo  (None, 64, 128, 256)         1024      ['conv2_block1_3_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv2_block1_add (Add)      (None, 64, 128, 256)         0         ['conv2_block1_0_bn[0][0]',   \n","                                                                     'conv2_block1_3_bn[0][0]']   \n","                                                                                                  \n"," conv2_block1_out (Activati  (None, 64, 128, 256)         0         ['conv2_block1_add[0][0]']    \n"," on)                                                                                              \n","                                                                                                  \n"," conv2_block2_1_conv (Conv2  (None, 64, 128, 64)          16448     ['conv2_block1_out[0][0]']    \n"," D)                                                                                               \n","                                                                                                  \n"," conv2_block2_1_bn (BatchNo  (None, 64, 128, 64)          256       ['conv2_block2_1_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv2_block2_1_relu (Activ  (None, 64, 128, 64)          0         ['conv2_block2_1_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv2_block2_2_conv (Conv2  (None, 64, 128, 64)          36928     ['conv2_block2_1_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv2_block2_2_bn (BatchNo  (None, 64, 128, 64)          256       ['conv2_block2_2_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv2_block2_2_relu (Activ  (None, 64, 128, 64)          0         ['conv2_block2_2_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv2_block2_3_conv (Conv2  (None, 64, 128, 256)         16640     ['conv2_block2_2_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv2_block2_3_bn (BatchNo  (None, 64, 128, 256)         1024      ['conv2_block2_3_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv2_block2_add (Add)      (None, 64, 128, 256)         0         ['conv2_block1_out[0][0]',    \n","                                                                     'conv2_block2_3_bn[0][0]']   \n","                                                                                                  \n"," conv2_block2_out (Activati  (None, 64, 128, 256)         0         ['conv2_block2_add[0][0]']    \n"," on)                                                                                              \n","                                                                                                  \n"," conv2_block3_1_conv (Conv2  (None, 64, 128, 64)          16448     ['conv2_block2_out[0][0]']    \n"," D)                                                                                               \n","                                                                                                  \n"," conv2_block3_1_bn (BatchNo  (None, 64, 128, 64)          256       ['conv2_block3_1_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv2_block3_1_relu (Activ  (None, 64, 128, 64)          0         ['conv2_block3_1_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv2_block3_2_conv (Conv2  (None, 64, 128, 64)          36928     ['conv2_block3_1_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv2_block3_2_bn (BatchNo  (None, 64, 128, 64)          256       ['conv2_block3_2_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv2_block3_2_relu (Activ  (None, 64, 128, 64)          0         ['conv2_block3_2_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv2_block3_3_conv (Conv2  (None, 64, 128, 256)         16640     ['conv2_block3_2_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv2_block3_3_bn (BatchNo  (None, 64, 128, 256)         1024      ['conv2_block3_3_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv2_block3_add (Add)      (None, 64, 128, 256)         0         ['conv2_block2_out[0][0]',    \n","                                                                     'conv2_block3_3_bn[0][0]']   \n","                                                                                                  \n"," conv2_block3_out (Activati  (None, 64, 128, 256)         0         ['conv2_block3_add[0][0]']    \n"," on)                                                                                              \n","                                                                                                  \n"," conv3_block1_1_conv (Conv2  (None, 32, 64, 128)          32896     ['conv2_block3_out[0][0]']    \n"," D)                                                                                               \n","                                                                                                  \n"," conv3_block1_1_bn (BatchNo  (None, 32, 64, 128)          512       ['conv3_block1_1_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv3_block1_1_relu (Activ  (None, 32, 64, 128)          0         ['conv3_block1_1_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv3_block1_2_conv (Conv2  (None, 32, 64, 128)          147584    ['conv3_block1_1_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv3_block1_2_bn (BatchNo  (None, 32, 64, 128)          512       ['conv3_block1_2_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv3_block1_2_relu (Activ  (None, 32, 64, 128)          0         ['conv3_block1_2_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv3_block1_0_conv (Conv2  (None, 32, 64, 512)          131584    ['conv2_block3_out[0][0]']    \n"," D)                                                                                               \n","                                                                                                  \n"," conv3_block1_3_conv (Conv2  (None, 32, 64, 512)          66048     ['conv3_block1_2_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv3_block1_0_bn (BatchNo  (None, 32, 64, 512)          2048      ['conv3_block1_0_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv3_block1_3_bn (BatchNo  (None, 32, 64, 512)          2048      ['conv3_block1_3_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv3_block1_add (Add)      (None, 32, 64, 512)          0         ['conv3_block1_0_bn[0][0]',   \n","                                                                     'conv3_block1_3_bn[0][0]']   \n","                                                                                                  \n"," conv3_block1_out (Activati  (None, 32, 64, 512)          0         ['conv3_block1_add[0][0]']    \n"," on)                                                                                              \n","                                                                                                  \n"," conv3_block2_1_conv (Conv2  (None, 32, 64, 128)          65664     ['conv3_block1_out[0][0]']    \n"," D)                                                                                               \n","                                                                                                  \n"," conv3_block2_1_bn (BatchNo  (None, 32, 64, 128)          512       ['conv3_block2_1_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv3_block2_1_relu (Activ  (None, 32, 64, 128)          0         ['conv3_block2_1_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv3_block2_2_conv (Conv2  (None, 32, 64, 128)          147584    ['conv3_block2_1_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv3_block2_2_bn (BatchNo  (None, 32, 64, 128)          512       ['conv3_block2_2_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv3_block2_2_relu (Activ  (None, 32, 64, 128)          0         ['conv3_block2_2_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv3_block2_3_conv (Conv2  (None, 32, 64, 512)          66048     ['conv3_block2_2_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv3_block2_3_bn (BatchNo  (None, 32, 64, 512)          2048      ['conv3_block2_3_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv3_block2_add (Add)      (None, 32, 64, 512)          0         ['conv3_block1_out[0][0]',    \n","                                                                     'conv3_block2_3_bn[0][0]']   \n","                                                                                                  \n"," conv3_block2_out (Activati  (None, 32, 64, 512)          0         ['conv3_block2_add[0][0]']    \n"," on)                                                                                              \n","                                                                                                  \n"," conv3_block3_1_conv (Conv2  (None, 32, 64, 128)          65664     ['conv3_block2_out[0][0]']    \n"," D)                                                                                               \n","                                                                                                  \n"," conv3_block3_1_bn (BatchNo  (None, 32, 64, 128)          512       ['conv3_block3_1_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv3_block3_1_relu (Activ  (None, 32, 64, 128)          0         ['conv3_block3_1_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv3_block3_2_conv (Conv2  (None, 32, 64, 128)          147584    ['conv3_block3_1_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv3_block3_2_bn (BatchNo  (None, 32, 64, 128)          512       ['conv3_block3_2_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv3_block3_2_relu (Activ  (None, 32, 64, 128)          0         ['conv3_block3_2_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv3_block3_3_conv (Conv2  (None, 32, 64, 512)          66048     ['conv3_block3_2_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv3_block3_3_bn (BatchNo  (None, 32, 64, 512)          2048      ['conv3_block3_3_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv3_block3_add (Add)      (None, 32, 64, 512)          0         ['conv3_block2_out[0][0]',    \n","                                                                     'conv3_block3_3_bn[0][0]']   \n","                                                                                                  \n"," conv3_block3_out (Activati  (None, 32, 64, 512)          0         ['conv3_block3_add[0][0]']    \n"," on)                                                                                              \n","                                                                                                  \n"," conv3_block4_1_conv (Conv2  (None, 32, 64, 128)          65664     ['conv3_block3_out[0][0]']    \n"," D)                                                                                               \n","                                                                                                  \n"," conv3_block4_1_bn (BatchNo  (None, 32, 64, 128)          512       ['conv3_block4_1_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv3_block4_1_relu (Activ  (None, 32, 64, 128)          0         ['conv3_block4_1_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv3_block4_2_conv (Conv2  (None, 32, 64, 128)          147584    ['conv3_block4_1_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv3_block4_2_bn (BatchNo  (None, 32, 64, 128)          512       ['conv3_block4_2_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv3_block4_2_relu (Activ  (None, 32, 64, 128)          0         ['conv3_block4_2_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv3_block4_3_conv (Conv2  (None, 32, 64, 512)          66048     ['conv3_block4_2_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv3_block4_3_bn (BatchNo  (None, 32, 64, 512)          2048      ['conv3_block4_3_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv3_block4_add (Add)      (None, 32, 64, 512)          0         ['conv3_block3_out[0][0]',    \n","                                                                     'conv3_block4_3_bn[0][0]']   \n","                                                                                                  \n"," conv3_block4_out (Activati  (None, 32, 64, 512)          0         ['conv3_block4_add[0][0]']    \n"," on)                                                                                              \n","                                                                                                  \n"," conv4_block1_1_conv (Conv2  (None, 16, 32, 256)          131328    ['conv3_block4_out[0][0]']    \n"," D)                                                                                               \n","                                                                                                  \n"," conv4_block1_1_bn (BatchNo  (None, 16, 32, 256)          1024      ['conv4_block1_1_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv4_block1_1_relu (Activ  (None, 16, 32, 256)          0         ['conv4_block1_1_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv4_block1_2_conv (Conv2  (None, 16, 32, 256)          590080    ['conv4_block1_1_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv4_block1_2_bn (BatchNo  (None, 16, 32, 256)          1024      ['conv4_block1_2_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv4_block1_2_relu (Activ  (None, 16, 32, 256)          0         ['conv4_block1_2_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv4_block1_0_conv (Conv2  (None, 16, 32, 1024)         525312    ['conv3_block4_out[0][0]']    \n"," D)                                                                                               \n","                                                                                                  \n"," conv4_block1_3_conv (Conv2  (None, 16, 32, 1024)         263168    ['conv4_block1_2_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv4_block1_0_bn (BatchNo  (None, 16, 32, 1024)         4096      ['conv4_block1_0_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv4_block1_3_bn (BatchNo  (None, 16, 32, 1024)         4096      ['conv4_block1_3_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv4_block1_add (Add)      (None, 16, 32, 1024)         0         ['conv4_block1_0_bn[0][0]',   \n","                                                                     'conv4_block1_3_bn[0][0]']   \n","                                                                                                  \n"," conv4_block1_out (Activati  (None, 16, 32, 1024)         0         ['conv4_block1_add[0][0]']    \n"," on)                                                                                              \n","                                                                                                  \n"," conv4_block2_1_conv (Conv2  (None, 16, 32, 256)          262400    ['conv4_block1_out[0][0]']    \n"," D)                                                                                               \n","                                                                                                  \n"," conv4_block2_1_bn (BatchNo  (None, 16, 32, 256)          1024      ['conv4_block2_1_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv4_block2_1_relu (Activ  (None, 16, 32, 256)          0         ['conv4_block2_1_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv4_block2_2_conv (Conv2  (None, 16, 32, 256)          590080    ['conv4_block2_1_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv4_block2_2_bn (BatchNo  (None, 16, 32, 256)          1024      ['conv4_block2_2_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv4_block2_2_relu (Activ  (None, 16, 32, 256)          0         ['conv4_block2_2_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv4_block2_3_conv (Conv2  (None, 16, 32, 1024)         263168    ['conv4_block2_2_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv4_block2_3_bn (BatchNo  (None, 16, 32, 1024)         4096      ['conv4_block2_3_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv4_block2_add (Add)      (None, 16, 32, 1024)         0         ['conv4_block1_out[0][0]',    \n","                                                                     'conv4_block2_3_bn[0][0]']   \n","                                                                                                  \n"," conv4_block2_out (Activati  (None, 16, 32, 1024)         0         ['conv4_block2_add[0][0]']    \n"," on)                                                                                              \n","                                                                                                  \n"," conv4_block3_1_conv (Conv2  (None, 16, 32, 256)          262400    ['conv4_block2_out[0][0]']    \n"," D)                                                                                               \n","                                                                                                  \n"," conv4_block3_1_bn (BatchNo  (None, 16, 32, 256)          1024      ['conv4_block3_1_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv4_block3_1_relu (Activ  (None, 16, 32, 256)          0         ['conv4_block3_1_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv4_block3_2_conv (Conv2  (None, 16, 32, 256)          590080    ['conv4_block3_1_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv4_block3_2_bn (BatchNo  (None, 16, 32, 256)          1024      ['conv4_block3_2_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv4_block3_2_relu (Activ  (None, 16, 32, 256)          0         ['conv4_block3_2_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv4_block3_3_conv (Conv2  (None, 16, 32, 1024)         263168    ['conv4_block3_2_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv4_block3_3_bn (BatchNo  (None, 16, 32, 1024)         4096      ['conv4_block3_3_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv4_block3_add (Add)      (None, 16, 32, 1024)         0         ['conv4_block2_out[0][0]',    \n","                                                                     'conv4_block3_3_bn[0][0]']   \n","                                                                                                  \n"," conv4_block3_out (Activati  (None, 16, 32, 1024)         0         ['conv4_block3_add[0][0]']    \n"," on)                                                                                              \n","                                                                                                  \n"," conv4_block4_1_conv (Conv2  (None, 16, 32, 256)          262400    ['conv4_block3_out[0][0]']    \n"," D)                                                                                               \n","                                                                                                  \n"," conv4_block4_1_bn (BatchNo  (None, 16, 32, 256)          1024      ['conv4_block4_1_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv4_block4_1_relu (Activ  (None, 16, 32, 256)          0         ['conv4_block4_1_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv4_block4_2_conv (Conv2  (None, 16, 32, 256)          590080    ['conv4_block4_1_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv4_block4_2_bn (BatchNo  (None, 16, 32, 256)          1024      ['conv4_block4_2_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv4_block4_2_relu (Activ  (None, 16, 32, 256)          0         ['conv4_block4_2_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv4_block4_3_conv (Conv2  (None, 16, 32, 1024)         263168    ['conv4_block4_2_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv4_block4_3_bn (BatchNo  (None, 16, 32, 1024)         4096      ['conv4_block4_3_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv4_block4_add (Add)      (None, 16, 32, 1024)         0         ['conv4_block3_out[0][0]',    \n","                                                                     'conv4_block4_3_bn[0][0]']   \n","                                                                                                  \n"," conv4_block4_out (Activati  (None, 16, 32, 1024)         0         ['conv4_block4_add[0][0]']    \n"," on)                                                                                              \n","                                                                                                  \n"," conv4_block5_1_conv (Conv2  (None, 16, 32, 256)          262400    ['conv4_block4_out[0][0]']    \n"," D)                                                                                               \n","                                                                                                  \n"," conv4_block5_1_bn (BatchNo  (None, 16, 32, 256)          1024      ['conv4_block5_1_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv4_block5_1_relu (Activ  (None, 16, 32, 256)          0         ['conv4_block5_1_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv4_block5_2_conv (Conv2  (None, 16, 32, 256)          590080    ['conv4_block5_1_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv4_block5_2_bn (BatchNo  (None, 16, 32, 256)          1024      ['conv4_block5_2_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv4_block5_2_relu (Activ  (None, 16, 32, 256)          0         ['conv4_block5_2_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv4_block5_3_conv (Conv2  (None, 16, 32, 1024)         263168    ['conv4_block5_2_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv4_block5_3_bn (BatchNo  (None, 16, 32, 1024)         4096      ['conv4_block5_3_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv4_block5_add (Add)      (None, 16, 32, 1024)         0         ['conv4_block4_out[0][0]',    \n","                                                                     'conv4_block5_3_bn[0][0]']   \n","                                                                                                  \n"," conv4_block5_out (Activati  (None, 16, 32, 1024)         0         ['conv4_block5_add[0][0]']    \n"," on)                                                                                              \n","                                                                                                  \n"," conv4_block6_1_conv (Conv2  (None, 16, 32, 256)          262400    ['conv4_block5_out[0][0]']    \n"," D)                                                                                               \n","                                                                                                  \n"," conv4_block6_1_bn (BatchNo  (None, 16, 32, 256)          1024      ['conv4_block6_1_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv4_block6_1_relu (Activ  (None, 16, 32, 256)          0         ['conv4_block6_1_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv4_block6_2_conv (Conv2  (None, 16, 32, 256)          590080    ['conv4_block6_1_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv4_block6_2_bn (BatchNo  (None, 16, 32, 256)          1024      ['conv4_block6_2_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv4_block6_2_relu (Activ  (None, 16, 32, 256)          0         ['conv4_block6_2_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv4_block6_3_conv (Conv2  (None, 16, 32, 1024)         263168    ['conv4_block6_2_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv4_block6_3_bn (BatchNo  (None, 16, 32, 1024)         4096      ['conv4_block6_3_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv4_block6_add (Add)      (None, 16, 32, 1024)         0         ['conv4_block5_out[0][0]',    \n","                                                                     'conv4_block6_3_bn[0][0]']   \n","                                                                                                  \n"," conv4_block6_out (Activati  (None, 16, 32, 1024)         0         ['conv4_block6_add[0][0]']    \n"," on)                                                                                              \n","                                                                                                  \n"," conv5_block1_1_conv (Conv2  (None, 8, 16, 512)           524800    ['conv4_block6_out[0][0]']    \n"," D)                                                                                               \n","                                                                                                  \n"," conv5_block1_1_bn (BatchNo  (None, 8, 16, 512)           2048      ['conv5_block1_1_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv5_block1_1_relu (Activ  (None, 8, 16, 512)           0         ['conv5_block1_1_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv5_block1_2_conv (Conv2  (None, 8, 16, 512)           2359808   ['conv5_block1_1_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv5_block1_2_bn (BatchNo  (None, 8, 16, 512)           2048      ['conv5_block1_2_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv5_block1_2_relu (Activ  (None, 8, 16, 512)           0         ['conv5_block1_2_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv5_block1_0_conv (Conv2  (None, 8, 16, 2048)          2099200   ['conv4_block6_out[0][0]']    \n"," D)                                                                                               \n","                                                                                                  \n"," conv5_block1_3_conv (Conv2  (None, 8, 16, 2048)          1050624   ['conv5_block1_2_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv5_block1_0_bn (BatchNo  (None, 8, 16, 2048)          8192      ['conv5_block1_0_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv5_block1_3_bn (BatchNo  (None, 8, 16, 2048)          8192      ['conv5_block1_3_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv5_block1_add (Add)      (None, 8, 16, 2048)          0         ['conv5_block1_0_bn[0][0]',   \n","                                                                     'conv5_block1_3_bn[0][0]']   \n","                                                                                                  \n"," conv5_block1_out (Activati  (None, 8, 16, 2048)          0         ['conv5_block1_add[0][0]']    \n"," on)                                                                                              \n","                                                                                                  \n"," conv5_block2_1_conv (Conv2  (None, 8, 16, 512)           1049088   ['conv5_block1_out[0][0]']    \n"," D)                                                                                               \n","                                                                                                  \n"," conv5_block2_1_bn (BatchNo  (None, 8, 16, 512)           2048      ['conv5_block2_1_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv5_block2_1_relu (Activ  (None, 8, 16, 512)           0         ['conv5_block2_1_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv5_block2_2_conv (Conv2  (None, 8, 16, 512)           2359808   ['conv5_block2_1_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv5_block2_2_bn (BatchNo  (None, 8, 16, 512)           2048      ['conv5_block2_2_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv5_block2_2_relu (Activ  (None, 8, 16, 512)           0         ['conv5_block2_2_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv5_block2_3_conv (Conv2  (None, 8, 16, 2048)          1050624   ['conv5_block2_2_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv5_block2_3_bn (BatchNo  (None, 8, 16, 2048)          8192      ['conv5_block2_3_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv5_block2_add (Add)      (None, 8, 16, 2048)          0         ['conv5_block1_out[0][0]',    \n","                                                                     'conv5_block2_3_bn[0][0]']   \n","                                                                                                  \n"," conv5_block2_out (Activati  (None, 8, 16, 2048)          0         ['conv5_block2_add[0][0]']    \n"," on)                                                                                              \n","                                                                                                  \n"," conv5_block3_1_conv (Conv2  (None, 8, 16, 512)           1049088   ['conv5_block2_out[0][0]']    \n"," D)                                                                                               \n","                                                                                                  \n"," conv5_block3_1_bn (BatchNo  (None, 8, 16, 512)           2048      ['conv5_block3_1_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv5_block3_1_relu (Activ  (None, 8, 16, 512)           0         ['conv5_block3_1_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv5_block3_2_conv (Conv2  (None, 8, 16, 512)           2359808   ['conv5_block3_1_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv5_block3_2_bn (BatchNo  (None, 8, 16, 512)           2048      ['conv5_block3_2_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv5_block3_2_relu (Activ  (None, 8, 16, 512)           0         ['conv5_block3_2_bn[0][0]']   \n"," ation)                                                                                           \n","                                                                                                  \n"," conv5_block3_3_conv (Conv2  (None, 8, 16, 2048)          1050624   ['conv5_block3_2_relu[0][0]'] \n"," D)                                                                                               \n","                                                                                                  \n"," conv5_block3_3_bn (BatchNo  (None, 8, 16, 2048)          8192      ['conv5_block3_3_conv[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv5_block3_add (Add)      (None, 8, 16, 2048)          0         ['conv5_block2_out[0][0]',    \n","                                                                     'conv5_block3_3_bn[0][0]']   \n","                                                                                                  \n"," conv5_block3_out (Activati  (None, 8, 16, 2048)          0         ['conv5_block3_add[0][0]']    \n"," on)                                                                                              \n","                                                                                                  \n"," avg_pool (GlobalAveragePoo  (None, 2048)                 0         ['conv5_block3_out[0][0]']    \n"," ling2D)                                                                                          \n","                                                                                                  \n"," predictions (Dense)         (None, 1000)                 2049000   ['avg_pool[0][0]']            \n","                                                                                                  \n","==================================================================================================\n","Total params: 25636712 (97.80 MB)\n","Trainable params: 25583592 (97.59 MB)\n","Non-trainable params: 53120 (207.50 KB)\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import math\n","# from models.resnet import resnet50\n","from torchvision.models import resnet50\n","\n","\n","class ProjectionMLP(nn.Module):\n","    def __init__(self, in_dim, mid_dim, out_dim):\n","        super(ProjectionMLP, self).__init__()\n","        self.l1 = nn.Sequential(\n","            nn.Linear(in_dim, mid_dim),\n","            nn.BatchNorm1d(mid_dim),\n","            nn.ReLU(inplace=True)\n","        )\n","        self.l2 = nn.Sequential(\n","            nn.Linear(mid_dim, mid_dim),\n","            nn.BatchNorm1d(mid_dim),\n","            nn.ReLU(inplace=True)\n","        )\n","        self.l3 = nn.Sequential(\n","            nn.Linear(mid_dim, out_dim),\n","            nn.BatchNorm1d(out_dim)\n","        )\n","\n","    def forward(self, x):\n","        x = self.l1(x)\n","        x = self.l2(x)\n","        x = self.l3(x)\n","\n","        return x\n","\n","\n","class PredictionMLP(nn.Module):\n","    def __init__(self, in_dim, mid_dim, out_dim):\n","        super(PredictionMLP, self).__init__()\n","        self.l1 = nn.Sequential(\n","            nn.Linear(in_dim, mid_dim),\n","            nn.BatchNorm1d(mid_dim),\n","            nn.ReLU(inplace=True)\n","        )\n","        self.l2 = nn.Linear(mid_dim, out_dim)\n","\n","    def forward(self, x):\n","        x = self.l1(x)\n","        x = self.l2(x)\n","\n","        return x\n","\n","\n","class SimSiam(nn.Module):\n","\n","    def __init__(self, backbone='resnet50', d=2048):\n","        super(SimSiam, self).__init__()\n","\n","        if backbone == 'resnet50':\n","            net = resnet50()\n","        else:\n","            raise NotImplementedError('Backbone model not implemented.')\n","\n","        num_ftrs = net.fc.in_features\n","        self.features = nn.Sequential(*list(net.children())[:-1])\n","        # num_ftrs = net.fc.out_features\n","        # self.features = net\n","\n","        # projection MLP\n","        self.projection = ProjectionMLP(num_ftrs, 2048, 2048)\n","        # prediction MLP\n","        self.prediction = PredictionMLP(2048, 512, 2048)\n","\n","        self.reset_parameters()\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = x.view(x.size(0), -1)\n","        # projection\n","        z = self.projection(x)\n","        # prediction\n","        p = self.prediction(z)\n","        return z, p\n","\n","    def reset_parameters(self):\n","        # reset conv initialization to default uniform initialization\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.in_channels\n","                stdv = 1. / math.sqrt(n)\n","                m.weight.data.uniform_(-stdv, stdv)\n","                if m.bias is not None:\n","                    m.bias.data.uniform_(-stdv, stdv)\n","            elif isinstance(m, nn.Linear):\n","                stdv = 1. / math.sqrt(m.weight.size(1))\n","                m.weight.data.uniform_(-stdv, stdv)\n","                if m.bias is not None:\n","                    m.bias.data.uniform_(-stdv, stdv)"],"metadata":{"id":"_Cc7kLJ2viWH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model2 = SimSiam()"],"metadata":{"id":"s31gIpz_vjWV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchsummary import summary\n","summary(model2, (3,512,512))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jbCBlFU5v6xH","executionInfo":{"status":"ok","timestamp":1712513448206,"user_tz":-120,"elapsed":4510,"user":{"displayName":"Ismael","userId":"03967480790510634870"}},"outputId":"1d8b3871-193a-49b7-dd68-282e4083d55a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 256, 256]           9,408\n","       BatchNorm2d-2         [-1, 64, 256, 256]             128\n","              ReLU-3         [-1, 64, 256, 256]               0\n","         MaxPool2d-4         [-1, 64, 128, 128]               0\n","            Conv2d-5         [-1, 64, 128, 128]           4,096\n","       BatchNorm2d-6         [-1, 64, 128, 128]             128\n","              ReLU-7         [-1, 64, 128, 128]               0\n","            Conv2d-8         [-1, 64, 128, 128]          36,864\n","       BatchNorm2d-9         [-1, 64, 128, 128]             128\n","             ReLU-10         [-1, 64, 128, 128]               0\n","           Conv2d-11        [-1, 256, 128, 128]          16,384\n","      BatchNorm2d-12        [-1, 256, 128, 128]             512\n","           Conv2d-13        [-1, 256, 128, 128]          16,384\n","      BatchNorm2d-14        [-1, 256, 128, 128]             512\n","             ReLU-15        [-1, 256, 128, 128]               0\n","       Bottleneck-16        [-1, 256, 128, 128]               0\n","           Conv2d-17         [-1, 64, 128, 128]          16,384\n","      BatchNorm2d-18         [-1, 64, 128, 128]             128\n","             ReLU-19         [-1, 64, 128, 128]               0\n","           Conv2d-20         [-1, 64, 128, 128]          36,864\n","      BatchNorm2d-21         [-1, 64, 128, 128]             128\n","             ReLU-22         [-1, 64, 128, 128]               0\n","           Conv2d-23        [-1, 256, 128, 128]          16,384\n","      BatchNorm2d-24        [-1, 256, 128, 128]             512\n","             ReLU-25        [-1, 256, 128, 128]               0\n","       Bottleneck-26        [-1, 256, 128, 128]               0\n","           Conv2d-27         [-1, 64, 128, 128]          16,384\n","      BatchNorm2d-28         [-1, 64, 128, 128]             128\n","             ReLU-29         [-1, 64, 128, 128]               0\n","           Conv2d-30         [-1, 64, 128, 128]          36,864\n","      BatchNorm2d-31         [-1, 64, 128, 128]             128\n","             ReLU-32         [-1, 64, 128, 128]               0\n","           Conv2d-33        [-1, 256, 128, 128]          16,384\n","      BatchNorm2d-34        [-1, 256, 128, 128]             512\n","             ReLU-35        [-1, 256, 128, 128]               0\n","       Bottleneck-36        [-1, 256, 128, 128]               0\n","           Conv2d-37        [-1, 128, 128, 128]          32,768\n","      BatchNorm2d-38        [-1, 128, 128, 128]             256\n","             ReLU-39        [-1, 128, 128, 128]               0\n","           Conv2d-40          [-1, 128, 64, 64]         147,456\n","      BatchNorm2d-41          [-1, 128, 64, 64]             256\n","             ReLU-42          [-1, 128, 64, 64]               0\n","           Conv2d-43          [-1, 512, 64, 64]          65,536\n","      BatchNorm2d-44          [-1, 512, 64, 64]           1,024\n","           Conv2d-45          [-1, 512, 64, 64]         131,072\n","      BatchNorm2d-46          [-1, 512, 64, 64]           1,024\n","             ReLU-47          [-1, 512, 64, 64]               0\n","       Bottleneck-48          [-1, 512, 64, 64]               0\n","           Conv2d-49          [-1, 128, 64, 64]          65,536\n","      BatchNorm2d-50          [-1, 128, 64, 64]             256\n","             ReLU-51          [-1, 128, 64, 64]               0\n","           Conv2d-52          [-1, 128, 64, 64]         147,456\n","      BatchNorm2d-53          [-1, 128, 64, 64]             256\n","             ReLU-54          [-1, 128, 64, 64]               0\n","           Conv2d-55          [-1, 512, 64, 64]          65,536\n","      BatchNorm2d-56          [-1, 512, 64, 64]           1,024\n","             ReLU-57          [-1, 512, 64, 64]               0\n","       Bottleneck-58          [-1, 512, 64, 64]               0\n","           Conv2d-59          [-1, 128, 64, 64]          65,536\n","      BatchNorm2d-60          [-1, 128, 64, 64]             256\n","             ReLU-61          [-1, 128, 64, 64]               0\n","           Conv2d-62          [-1, 128, 64, 64]         147,456\n","      BatchNorm2d-63          [-1, 128, 64, 64]             256\n","             ReLU-64          [-1, 128, 64, 64]               0\n","           Conv2d-65          [-1, 512, 64, 64]          65,536\n","      BatchNorm2d-66          [-1, 512, 64, 64]           1,024\n","             ReLU-67          [-1, 512, 64, 64]               0\n","       Bottleneck-68          [-1, 512, 64, 64]               0\n","           Conv2d-69          [-1, 128, 64, 64]          65,536\n","      BatchNorm2d-70          [-1, 128, 64, 64]             256\n","             ReLU-71          [-1, 128, 64, 64]               0\n","           Conv2d-72          [-1, 128, 64, 64]         147,456\n","      BatchNorm2d-73          [-1, 128, 64, 64]             256\n","             ReLU-74          [-1, 128, 64, 64]               0\n","           Conv2d-75          [-1, 512, 64, 64]          65,536\n","      BatchNorm2d-76          [-1, 512, 64, 64]           1,024\n","             ReLU-77          [-1, 512, 64, 64]               0\n","       Bottleneck-78          [-1, 512, 64, 64]               0\n","           Conv2d-79          [-1, 256, 64, 64]         131,072\n","      BatchNorm2d-80          [-1, 256, 64, 64]             512\n","             ReLU-81          [-1, 256, 64, 64]               0\n","           Conv2d-82          [-1, 256, 32, 32]         589,824\n","      BatchNorm2d-83          [-1, 256, 32, 32]             512\n","             ReLU-84          [-1, 256, 32, 32]               0\n","           Conv2d-85         [-1, 1024, 32, 32]         262,144\n","      BatchNorm2d-86         [-1, 1024, 32, 32]           2,048\n","           Conv2d-87         [-1, 1024, 32, 32]         524,288\n","      BatchNorm2d-88         [-1, 1024, 32, 32]           2,048\n","             ReLU-89         [-1, 1024, 32, 32]               0\n","       Bottleneck-90         [-1, 1024, 32, 32]               0\n","           Conv2d-91          [-1, 256, 32, 32]         262,144\n","      BatchNorm2d-92          [-1, 256, 32, 32]             512\n","             ReLU-93          [-1, 256, 32, 32]               0\n","           Conv2d-94          [-1, 256, 32, 32]         589,824\n","      BatchNorm2d-95          [-1, 256, 32, 32]             512\n","             ReLU-96          [-1, 256, 32, 32]               0\n","           Conv2d-97         [-1, 1024, 32, 32]         262,144\n","      BatchNorm2d-98         [-1, 1024, 32, 32]           2,048\n","             ReLU-99         [-1, 1024, 32, 32]               0\n","      Bottleneck-100         [-1, 1024, 32, 32]               0\n","          Conv2d-101          [-1, 256, 32, 32]         262,144\n","     BatchNorm2d-102          [-1, 256, 32, 32]             512\n","            ReLU-103          [-1, 256, 32, 32]               0\n","          Conv2d-104          [-1, 256, 32, 32]         589,824\n","     BatchNorm2d-105          [-1, 256, 32, 32]             512\n","            ReLU-106          [-1, 256, 32, 32]               0\n","          Conv2d-107         [-1, 1024, 32, 32]         262,144\n","     BatchNorm2d-108         [-1, 1024, 32, 32]           2,048\n","            ReLU-109         [-1, 1024, 32, 32]               0\n","      Bottleneck-110         [-1, 1024, 32, 32]               0\n","          Conv2d-111          [-1, 256, 32, 32]         262,144\n","     BatchNorm2d-112          [-1, 256, 32, 32]             512\n","            ReLU-113          [-1, 256, 32, 32]               0\n","          Conv2d-114          [-1, 256, 32, 32]         589,824\n","     BatchNorm2d-115          [-1, 256, 32, 32]             512\n","            ReLU-116          [-1, 256, 32, 32]               0\n","          Conv2d-117         [-1, 1024, 32, 32]         262,144\n","     BatchNorm2d-118         [-1, 1024, 32, 32]           2,048\n","            ReLU-119         [-1, 1024, 32, 32]               0\n","      Bottleneck-120         [-1, 1024, 32, 32]               0\n","          Conv2d-121          [-1, 256, 32, 32]         262,144\n","     BatchNorm2d-122          [-1, 256, 32, 32]             512\n","            ReLU-123          [-1, 256, 32, 32]               0\n","          Conv2d-124          [-1, 256, 32, 32]         589,824\n","     BatchNorm2d-125          [-1, 256, 32, 32]             512\n","            ReLU-126          [-1, 256, 32, 32]               0\n","          Conv2d-127         [-1, 1024, 32, 32]         262,144\n","     BatchNorm2d-128         [-1, 1024, 32, 32]           2,048\n","            ReLU-129         [-1, 1024, 32, 32]               0\n","      Bottleneck-130         [-1, 1024, 32, 32]               0\n","          Conv2d-131          [-1, 256, 32, 32]         262,144\n","     BatchNorm2d-132          [-1, 256, 32, 32]             512\n","            ReLU-133          [-1, 256, 32, 32]               0\n","          Conv2d-134          [-1, 256, 32, 32]         589,824\n","     BatchNorm2d-135          [-1, 256, 32, 32]             512\n","            ReLU-136          [-1, 256, 32, 32]               0\n","          Conv2d-137         [-1, 1024, 32, 32]         262,144\n","     BatchNorm2d-138         [-1, 1024, 32, 32]           2,048\n","            ReLU-139         [-1, 1024, 32, 32]               0\n","      Bottleneck-140         [-1, 1024, 32, 32]               0\n","          Conv2d-141          [-1, 512, 32, 32]         524,288\n","     BatchNorm2d-142          [-1, 512, 32, 32]           1,024\n","            ReLU-143          [-1, 512, 32, 32]               0\n","          Conv2d-144          [-1, 512, 16, 16]       2,359,296\n","     BatchNorm2d-145          [-1, 512, 16, 16]           1,024\n","            ReLU-146          [-1, 512, 16, 16]               0\n","          Conv2d-147         [-1, 2048, 16, 16]       1,048,576\n","     BatchNorm2d-148         [-1, 2048, 16, 16]           4,096\n","          Conv2d-149         [-1, 2048, 16, 16]       2,097,152\n","     BatchNorm2d-150         [-1, 2048, 16, 16]           4,096\n","            ReLU-151         [-1, 2048, 16, 16]               0\n","      Bottleneck-152         [-1, 2048, 16, 16]               0\n","          Conv2d-153          [-1, 512, 16, 16]       1,048,576\n","     BatchNorm2d-154          [-1, 512, 16, 16]           1,024\n","            ReLU-155          [-1, 512, 16, 16]               0\n","          Conv2d-156          [-1, 512, 16, 16]       2,359,296\n","     BatchNorm2d-157          [-1, 512, 16, 16]           1,024\n","            ReLU-158          [-1, 512, 16, 16]               0\n","          Conv2d-159         [-1, 2048, 16, 16]       1,048,576\n","     BatchNorm2d-160         [-1, 2048, 16, 16]           4,096\n","            ReLU-161         [-1, 2048, 16, 16]               0\n","      Bottleneck-162         [-1, 2048, 16, 16]               0\n","          Conv2d-163          [-1, 512, 16, 16]       1,048,576\n","     BatchNorm2d-164          [-1, 512, 16, 16]           1,024\n","            ReLU-165          [-1, 512, 16, 16]               0\n","          Conv2d-166          [-1, 512, 16, 16]       2,359,296\n","     BatchNorm2d-167          [-1, 512, 16, 16]           1,024\n","            ReLU-168          [-1, 512, 16, 16]               0\n","          Conv2d-169         [-1, 2048, 16, 16]       1,048,576\n","     BatchNorm2d-170         [-1, 2048, 16, 16]           4,096\n","            ReLU-171         [-1, 2048, 16, 16]               0\n","      Bottleneck-172         [-1, 2048, 16, 16]               0\n","AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n","          Linear-174                 [-1, 2048]       4,196,352\n","     BatchNorm1d-175                 [-1, 2048]           4,096\n","            ReLU-176                 [-1, 2048]               0\n","          Linear-177                 [-1, 2048]       4,196,352\n","     BatchNorm1d-178                 [-1, 2048]           4,096\n","            ReLU-179                 [-1, 2048]               0\n","          Linear-180                 [-1, 2048]       4,196,352\n","     BatchNorm1d-181                 [-1, 2048]           4,096\n","   ProjectionMLP-182                 [-1, 2048]               0\n","          Linear-183                  [-1, 512]       1,049,088\n","     BatchNorm1d-184                  [-1, 512]           1,024\n","            ReLU-185                  [-1, 512]               0\n","          Linear-186                 [-1, 2048]       1,050,624\n","   PredictionMLP-187                 [-1, 2048]               0\n","================================================================\n","Total params: 38,210,112\n","Trainable params: 38,210,112\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 3.00\n","Forward/backward pass size (MB): 1497.20\n","Params size (MB): 145.76\n","Estimated Total Size (MB): 1645.96\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import math\n","# from models.resnet import resnet50\n","from torchvision.models import resnet50, resnet18"],"metadata":{"id":"N0Hx7evUxBtF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["net = resnet50()"],"metadata":{"id":"iTtwRf3rdmwQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["feature_maps = nn.Sequential(*list(net.children()))\n","print(feature_maps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kzXqnVK9qtc2","executionInfo":{"status":"ok","timestamp":1714813640143,"user_tz":-120,"elapsed":267,"user":{"displayName":"Ismael","userId":"03967480790510634870"}},"outputId":"e1fd7318-3081-45db-f8f3-e9d3becd51b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequential(\n","  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (2): ReLU(inplace=True)\n","  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (5): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (6): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (7): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (9): Linear(in_features=2048, out_features=1000, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["hola = list(net.children())[:-2]"],"metadata":{"id":"u1nxew5odwj1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(hola[7])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"7RUzL65buAec","executionInfo":{"status":"error","timestamp":1713887765589,"user_tz":-120,"elapsed":209,"user":{"displayName":"Ismael","userId":"03967480790510634870"}},"outputId":"93c24320-d7d9-46a5-e41e-4be650a829c6"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'hola' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-0fe0ea8ee8a0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhola\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'hola' is not defined"]}]},{"cell_type":"code","source":["nueva_lista = copy.deepcopy(hola)\n","for i, layer in enumerate(nueva_lista):\n","    if isinstance(layer, nn.Sequential):\n","        for j, sub_layer in enumerate(layer):\n","            if j == len(layer) - 1 and i == len(nueva_lista) - 1:\n","                # Eliminar los atributos conv3 y bn3 del ltimo sub_layer de la ltima secuencia\n","                delattr(sub_layer, 'conv3')\n","                delattr(sub_layer, 'bn3')"],"metadata":{"id":"mNosCuNC4Jqf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(nueva_lista)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W8nn0P184YaN","executionInfo":{"status":"ok","timestamp":1713807402337,"user_tz":-120,"elapsed":307,"user":{"displayName":"Ismael","userId":"03967480790510634870"}},"outputId":"e17c4fc9-c4b5-4062-c8e5-c75c767e72f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False), Sequential(\n","  (0): Bottleneck(\n","    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (downsample): Sequential(\n","      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (1): Bottleneck(\n","    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","  (2): Bottleneck(\n","    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","), Sequential(\n","  (0): Bottleneck(\n","    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (downsample): Sequential(\n","      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (1): Bottleneck(\n","    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","  (2): Bottleneck(\n","    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","  (3): Bottleneck(\n","    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","), Sequential(\n","  (0): Bottleneck(\n","    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (downsample): Sequential(\n","      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (1): Bottleneck(\n","    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","  (2): Bottleneck(\n","    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","  (3): Bottleneck(\n","    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","  (4): Bottleneck(\n","    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","  (5): Bottleneck(\n","    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","), Sequential(\n","  (0): Bottleneck(\n","    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (downsample): Sequential(\n","      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (1): Bottleneck(\n","    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","  (2): Bottleneck(\n","    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n",")]\n"]}]},{"cell_type":"code","source":["nueva_lista = hola.copy()\n","\n","for i in range(len(nueva_lista)):\n","    if isinstance(nueva_lista[i], nn.Sequential):\n","        for j in range(len(nueva_lista[i])):\n","                # Eliminar el ltimo relu si es el ltimo bottleneck del ltimo sequential\n","                if j == len(nueva_lista[i]) - 1 and i == len(nueva_lista) -1:\n","                  del nueva_lista[i][j].conv3\n","                  del nueva_lista[i][j].bn3\n","\n","print(nueva_lista)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ss4WcZZnox6b","executionInfo":{"status":"ok","timestamp":1713804842191,"user_tz":-120,"elapsed":236,"user":{"displayName":"Ismael","userId":"03967480790510634870"}},"outputId":"2b237241-36ea-4f43-8153-f6be787b0a81"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False), Sequential(\n","  (0): Bottleneck(\n","    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (downsample): Sequential(\n","      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (1): Bottleneck(\n","    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","  (2): Bottleneck(\n","    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","), Sequential(\n","  (0): Bottleneck(\n","    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (downsample): Sequential(\n","      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (1): Bottleneck(\n","    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","  (2): Bottleneck(\n","    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","  (3): Bottleneck(\n","    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","), Sequential(\n","  (0): Bottleneck(\n","    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (downsample): Sequential(\n","      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (1): Bottleneck(\n","    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","  (2): Bottleneck(\n","    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","  (3): Bottleneck(\n","    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","  (4): Bottleneck(\n","    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","  (5): Bottleneck(\n","    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","), Sequential(\n","  (0): Bottleneck(\n","    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (downsample): Sequential(\n","      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (1): Bottleneck(\n","    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","  (2): Bottleneck(\n","    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n",")]\n"]}]},{"cell_type":"code","source":["import copy\n","import torchvision\n","\n","new_net_children = []\n","\n","for i, module in enumerate(hola):\n","    if isinstance(module, nn.Sequential):\n","        new_module = []\n","        for j, bottleneck in enumerate(module):\n","            if j == len(module) - 1 and i == len(hola) - 1:\n","                # No incluir conv3 y bn3 para eliminarlos solo para el ltimo bloque\n","                new_bottleneck = torchvision.models.resnet.Bottleneck(\n","                    conv1=copy.deepcopy(bottleneck.conv1),\n","                    bn1=copy.deepcopy(bottleneck.bn1),\n","                    conv2=copy.deepcopy(bottleneck.conv2),\n","                    bn2=copy.deepcopy(bottleneck.bn2),\n","                    relu=copy.deepcopy(bottleneck.relu)\n","                )\n","                new_module.append(new_bottleneck)\n","            else:\n","                new_module.append(copy.deepcopy(bottleneck))\n","        new_net_children.append(nn.Sequential(*new_module))\n","    else:\n","        new_net_children.append(copy.deepcopy(module))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"Qi6L0s4_17ve","executionInfo":{"status":"error","timestamp":1713806901349,"user_tz":-120,"elapsed":605,"user":{"displayName":"Ismael","userId":"03967480790510634870"}},"outputId":"23b15669-4057-4683-b206-c46ab27c9412"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"Bottleneck.__init__() got an unexpected keyword argument 'conv1'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-75-d2f9a7a04ee9>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhola\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;31m# No incluir conv3 y bn3 para eliminarlos solo para el ltimo bloque\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 new_bottleneck = torchvision.models.resnet.Bottleneck(\n\u001b[0m\u001b[1;32m     13\u001b[0m                     \u001b[0mconv1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbottleneck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mbn1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbottleneck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Bottleneck.__init__() got an unexpected keyword argument 'conv1'"]}]},{"cell_type":"code","source":["print(list(hola[-1][-1].children())[:-3])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"05QI3YKfTisN","executionInfo":{"status":"ok","timestamp":1713804318751,"user_tz":-120,"elapsed":259,"user":{"displayName":"Ismael","userId":"03967480790510634870"}},"outputId":"2fc9251c-3187-4633-a49e-8ded09e12800"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)]\n"]}]},{"cell_type":"code","source":["print(hola[:][:-1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uhR2en02dyXK","executionInfo":{"status":"ok","timestamp":1713797660855,"user_tz":-120,"elapsed":306,"user":{"displayName":"Ismael","userId":"03967480790510634870"}},"outputId":"2728e194-13a3-4baa-dc2d-ef14eaa0a6e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False), Sequential(\n","  (0): Bottleneck(\n","    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (downsample): Sequential(\n","      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (1): Bottleneck(\n","    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","  (2): Bottleneck(\n","    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","), Sequential(\n","  (0): Bottleneck(\n","    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (downsample): Sequential(\n","      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (1): Bottleneck(\n","    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","  (2): Bottleneck(\n","    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","  (3): Bottleneck(\n","    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","), Sequential(\n","  (0): Bottleneck(\n","    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (downsample): Sequential(\n","      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (1): Bottleneck(\n","    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","  (2): Bottleneck(\n","    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","  (3): Bottleneck(\n","    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","  (4): Bottleneck(\n","    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n","  (5): Bottleneck(\n","    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","  )\n",")]\n"]}]},{"cell_type":"code","source":["from torchsummary import summary\n","summary(net, (3,512, 1024))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xQGm2vS9ePe3","executionInfo":{"status":"ok","timestamp":1714814012209,"user_tz":-120,"elapsed":6891,"user":{"displayName":"Ismael","userId":"03967480790510634870"}},"outputId":"6b81bd91-3593-4169-c595-28ba47fe2d4e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 256, 512]           9,408\n","       BatchNorm2d-2         [-1, 64, 256, 512]             128\n","              ReLU-3         [-1, 64, 256, 512]               0\n","         MaxPool2d-4         [-1, 64, 128, 256]               0\n","            Conv2d-5         [-1, 64, 128, 256]           4,096\n","       BatchNorm2d-6         [-1, 64, 128, 256]             128\n","              ReLU-7         [-1, 64, 128, 256]               0\n","            Conv2d-8         [-1, 64, 128, 256]          36,864\n","       BatchNorm2d-9         [-1, 64, 128, 256]             128\n","             ReLU-10         [-1, 64, 128, 256]               0\n","           Conv2d-11        [-1, 256, 128, 256]          16,384\n","      BatchNorm2d-12        [-1, 256, 128, 256]             512\n","           Conv2d-13        [-1, 256, 128, 256]          16,384\n","      BatchNorm2d-14        [-1, 256, 128, 256]             512\n","             ReLU-15        [-1, 256, 128, 256]               0\n","       Bottleneck-16        [-1, 256, 128, 256]               0\n","           Conv2d-17         [-1, 64, 128, 256]          16,384\n","      BatchNorm2d-18         [-1, 64, 128, 256]             128\n","             ReLU-19         [-1, 64, 128, 256]               0\n","           Conv2d-20         [-1, 64, 128, 256]          36,864\n","      BatchNorm2d-21         [-1, 64, 128, 256]             128\n","             ReLU-22         [-1, 64, 128, 256]               0\n","           Conv2d-23        [-1, 256, 128, 256]          16,384\n","      BatchNorm2d-24        [-1, 256, 128, 256]             512\n","             ReLU-25        [-1, 256, 128, 256]               0\n","       Bottleneck-26        [-1, 256, 128, 256]               0\n","           Conv2d-27         [-1, 64, 128, 256]          16,384\n","      BatchNorm2d-28         [-1, 64, 128, 256]             128\n","             ReLU-29         [-1, 64, 128, 256]               0\n","           Conv2d-30         [-1, 64, 128, 256]          36,864\n","      BatchNorm2d-31         [-1, 64, 128, 256]             128\n","             ReLU-32         [-1, 64, 128, 256]               0\n","           Conv2d-33        [-1, 256, 128, 256]          16,384\n","      BatchNorm2d-34        [-1, 256, 128, 256]             512\n","             ReLU-35        [-1, 256, 128, 256]               0\n","       Bottleneck-36        [-1, 256, 128, 256]               0\n","           Conv2d-37        [-1, 128, 128, 256]          32,768\n","      BatchNorm2d-38        [-1, 128, 128, 256]             256\n","             ReLU-39        [-1, 128, 128, 256]               0\n","           Conv2d-40         [-1, 128, 64, 128]         147,456\n","      BatchNorm2d-41         [-1, 128, 64, 128]             256\n","             ReLU-42         [-1, 128, 64, 128]               0\n","           Conv2d-43         [-1, 512, 64, 128]          65,536\n","      BatchNorm2d-44         [-1, 512, 64, 128]           1,024\n","           Conv2d-45         [-1, 512, 64, 128]         131,072\n","      BatchNorm2d-46         [-1, 512, 64, 128]           1,024\n","             ReLU-47         [-1, 512, 64, 128]               0\n","       Bottleneck-48         [-1, 512, 64, 128]               0\n","           Conv2d-49         [-1, 128, 64, 128]          65,536\n","      BatchNorm2d-50         [-1, 128, 64, 128]             256\n","             ReLU-51         [-1, 128, 64, 128]               0\n","           Conv2d-52         [-1, 128, 64, 128]         147,456\n","      BatchNorm2d-53         [-1, 128, 64, 128]             256\n","             ReLU-54         [-1, 128, 64, 128]               0\n","           Conv2d-55         [-1, 512, 64, 128]          65,536\n","      BatchNorm2d-56         [-1, 512, 64, 128]           1,024\n","             ReLU-57         [-1, 512, 64, 128]               0\n","       Bottleneck-58         [-1, 512, 64, 128]               0\n","           Conv2d-59         [-1, 128, 64, 128]          65,536\n","      BatchNorm2d-60         [-1, 128, 64, 128]             256\n","             ReLU-61         [-1, 128, 64, 128]               0\n","           Conv2d-62         [-1, 128, 64, 128]         147,456\n","      BatchNorm2d-63         [-1, 128, 64, 128]             256\n","             ReLU-64         [-1, 128, 64, 128]               0\n","           Conv2d-65         [-1, 512, 64, 128]          65,536\n","      BatchNorm2d-66         [-1, 512, 64, 128]           1,024\n","             ReLU-67         [-1, 512, 64, 128]               0\n","       Bottleneck-68         [-1, 512, 64, 128]               0\n","           Conv2d-69         [-1, 128, 64, 128]          65,536\n","      BatchNorm2d-70         [-1, 128, 64, 128]             256\n","             ReLU-71         [-1, 128, 64, 128]               0\n","           Conv2d-72         [-1, 128, 64, 128]         147,456\n","      BatchNorm2d-73         [-1, 128, 64, 128]             256\n","             ReLU-74         [-1, 128, 64, 128]               0\n","           Conv2d-75         [-1, 512, 64, 128]          65,536\n","      BatchNorm2d-76         [-1, 512, 64, 128]           1,024\n","             ReLU-77         [-1, 512, 64, 128]               0\n","       Bottleneck-78         [-1, 512, 64, 128]               0\n","           Conv2d-79         [-1, 256, 64, 128]         131,072\n","      BatchNorm2d-80         [-1, 256, 64, 128]             512\n","             ReLU-81         [-1, 256, 64, 128]               0\n","           Conv2d-82          [-1, 256, 32, 64]         589,824\n","      BatchNorm2d-83          [-1, 256, 32, 64]             512\n","             ReLU-84          [-1, 256, 32, 64]               0\n","           Conv2d-85         [-1, 1024, 32, 64]         262,144\n","      BatchNorm2d-86         [-1, 1024, 32, 64]           2,048\n","           Conv2d-87         [-1, 1024, 32, 64]         524,288\n","      BatchNorm2d-88         [-1, 1024, 32, 64]           2,048\n","             ReLU-89         [-1, 1024, 32, 64]               0\n","       Bottleneck-90         [-1, 1024, 32, 64]               0\n","           Conv2d-91          [-1, 256, 32, 64]         262,144\n","      BatchNorm2d-92          [-1, 256, 32, 64]             512\n","             ReLU-93          [-1, 256, 32, 64]               0\n","           Conv2d-94          [-1, 256, 32, 64]         589,824\n","      BatchNorm2d-95          [-1, 256, 32, 64]             512\n","             ReLU-96          [-1, 256, 32, 64]               0\n","           Conv2d-97         [-1, 1024, 32, 64]         262,144\n","      BatchNorm2d-98         [-1, 1024, 32, 64]           2,048\n","             ReLU-99         [-1, 1024, 32, 64]               0\n","      Bottleneck-100         [-1, 1024, 32, 64]               0\n","          Conv2d-101          [-1, 256, 32, 64]         262,144\n","     BatchNorm2d-102          [-1, 256, 32, 64]             512\n","            ReLU-103          [-1, 256, 32, 64]               0\n","          Conv2d-104          [-1, 256, 32, 64]         589,824\n","     BatchNorm2d-105          [-1, 256, 32, 64]             512\n","            ReLU-106          [-1, 256, 32, 64]               0\n","          Conv2d-107         [-1, 1024, 32, 64]         262,144\n","     BatchNorm2d-108         [-1, 1024, 32, 64]           2,048\n","            ReLU-109         [-1, 1024, 32, 64]               0\n","      Bottleneck-110         [-1, 1024, 32, 64]               0\n","          Conv2d-111          [-1, 256, 32, 64]         262,144\n","     BatchNorm2d-112          [-1, 256, 32, 64]             512\n","            ReLU-113          [-1, 256, 32, 64]               0\n","          Conv2d-114          [-1, 256, 32, 64]         589,824\n","     BatchNorm2d-115          [-1, 256, 32, 64]             512\n","            ReLU-116          [-1, 256, 32, 64]               0\n","          Conv2d-117         [-1, 1024, 32, 64]         262,144\n","     BatchNorm2d-118         [-1, 1024, 32, 64]           2,048\n","            ReLU-119         [-1, 1024, 32, 64]               0\n","      Bottleneck-120         [-1, 1024, 32, 64]               0\n","          Conv2d-121          [-1, 256, 32, 64]         262,144\n","     BatchNorm2d-122          [-1, 256, 32, 64]             512\n","            ReLU-123          [-1, 256, 32, 64]               0\n","          Conv2d-124          [-1, 256, 32, 64]         589,824\n","     BatchNorm2d-125          [-1, 256, 32, 64]             512\n","            ReLU-126          [-1, 256, 32, 64]               0\n","          Conv2d-127         [-1, 1024, 32, 64]         262,144\n","     BatchNorm2d-128         [-1, 1024, 32, 64]           2,048\n","            ReLU-129         [-1, 1024, 32, 64]               0\n","      Bottleneck-130         [-1, 1024, 32, 64]               0\n","          Conv2d-131          [-1, 256, 32, 64]         262,144\n","     BatchNorm2d-132          [-1, 256, 32, 64]             512\n","            ReLU-133          [-1, 256, 32, 64]               0\n","          Conv2d-134          [-1, 256, 32, 64]         589,824\n","     BatchNorm2d-135          [-1, 256, 32, 64]             512\n","            ReLU-136          [-1, 256, 32, 64]               0\n","          Conv2d-137         [-1, 1024, 32, 64]         262,144\n","     BatchNorm2d-138         [-1, 1024, 32, 64]           2,048\n","            ReLU-139         [-1, 1024, 32, 64]               0\n","      Bottleneck-140         [-1, 1024, 32, 64]               0\n","          Conv2d-141          [-1, 512, 32, 64]         524,288\n","     BatchNorm2d-142          [-1, 512, 32, 64]           1,024\n","            ReLU-143          [-1, 512, 32, 64]               0\n","          Conv2d-144          [-1, 512, 16, 32]       2,359,296\n","     BatchNorm2d-145          [-1, 512, 16, 32]           1,024\n","            ReLU-146          [-1, 512, 16, 32]               0\n","          Conv2d-147         [-1, 2048, 16, 32]       1,048,576\n","     BatchNorm2d-148         [-1, 2048, 16, 32]           4,096\n","          Conv2d-149         [-1, 2048, 16, 32]       2,097,152\n","     BatchNorm2d-150         [-1, 2048, 16, 32]           4,096\n","            ReLU-151         [-1, 2048, 16, 32]               0\n","      Bottleneck-152         [-1, 2048, 16, 32]               0\n","          Conv2d-153          [-1, 512, 16, 32]       1,048,576\n","     BatchNorm2d-154          [-1, 512, 16, 32]           1,024\n","            ReLU-155          [-1, 512, 16, 32]               0\n","          Conv2d-156          [-1, 512, 16, 32]       2,359,296\n","     BatchNorm2d-157          [-1, 512, 16, 32]           1,024\n","            ReLU-158          [-1, 512, 16, 32]               0\n","          Conv2d-159         [-1, 2048, 16, 32]       1,048,576\n","     BatchNorm2d-160         [-1, 2048, 16, 32]           4,096\n","            ReLU-161         [-1, 2048, 16, 32]               0\n","      Bottleneck-162         [-1, 2048, 16, 32]               0\n","          Conv2d-163          [-1, 512, 16, 32]       1,048,576\n","     BatchNorm2d-164          [-1, 512, 16, 32]           1,024\n","            ReLU-165          [-1, 512, 16, 32]               0\n","          Conv2d-166          [-1, 512, 16, 32]       2,359,296\n","     BatchNorm2d-167          [-1, 512, 16, 32]           1,024\n","            ReLU-168          [-1, 512, 16, 32]               0\n","          Conv2d-169         [-1, 2048, 16, 32]       1,048,576\n","     BatchNorm2d-170         [-1, 2048, 16, 32]           4,096\n","            ReLU-171         [-1, 2048, 16, 32]               0\n","      Bottleneck-172         [-1, 2048, 16, 32]               0\n","AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n","          Linear-174                 [-1, 1000]       2,049,000\n","================================================================\n","Total params: 25,557,032\n","Trainable params: 25,557,032\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 6.00\n","Forward/backward pass size (MB): 2994.02\n","Params size (MB): 97.49\n","Estimated Total Size (MB): 3097.52\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["!pip install -q vit-pytorch\n","!pip install -q tqdm"],"metadata":{"id":"p0Xmlb4hjlaX","executionInfo":{"status":"ok","timestamp":1713122023387,"user_tz":-120,"elapsed":61257,"user":{"displayName":"Ismael","userId":"03967480790510634870"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"50cf4a58-aeac-4daa-c168-b21fccde7be5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m\u001b[0m \u001b[32m0.0/100.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m30.7/100.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m\u001b[0m \u001b[32m100.3/100.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l     \u001b[90m\u001b[0m \u001b[32m0.0/44.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import numpy as np\n","import os\n","from torch.utils.data import Dataset\n","import torch\n","import torch.nn.functional as F\n","import torchvision.transforms.functional as TF"],"metadata":{"id":"yDz8jq5Vlqtz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import skimage\n","from skimage import io\n","\n","def is_png_file(filename):\n","    return any(filename.endswith(extension) for extension in [\".png\"])\n","\n","def load_img(filepath):\n","    img = io.imread(filepath)\n","    img = img.astype(np.float32)\n","    #img = img/255.\n","    '''for i in range(img.shape[-1]):  # Z-Score normalization for every channel\n","        mean = img[:,:,i].mean()\n","        std = img[:,:,i].std()\n","        img[:,:,i] -= mean\n","        img /= (max(std, 1e-8))'''\n","    return img"],"metadata":{"id":"NSu0rFrtmGVT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DataLoaderTrain(Dataset):\n","    def __init__(self, rgb_dir):\n","        super(DataLoaderTrain, self).__init__()\n","\n","        input_files = sorted(os.listdir(rgb_dir))\n","\n","        self.input_filenames = [os.path.join(rgb_dir, x) for x in input_files if is_png_file(x)]\n","\n","        self.tar_size = len(self.input_filenames)  # get the size of target\n","\n","    def __len__(self):\n","        return self.tar_size\n","\n","    def __getitem__(self, index):\n","        tar_index   = index % self.tar_size\n","        input = np.float32(load_img(self.input_filenames[tar_index]))\n","        mean = input.mean()\n","        std = input.std()\n","        input -= mean\n","        input /= (max(std, 1e-8))\n","        input = torch.from_numpy(input)\n","\n","        input = input.permute(2,0,1)\n","\n","        input_filename = os.path.split(self.input_filenames[tar_index])[-1]\n","\n","        return input, input_filename"],"metadata":{"id":"wKeKQhsGliel"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_training_data(rgb_dir):\n","    assert os.path.exists(rgb_dir)\n","    return DataLoaderTrain(rgb_dir)"],"metadata":{"id":"qAK9s97Omwtb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","train_dataset = get_training_data('/content/drive/MyDrive/TFG/Uformer/V2/dataV3/CholecSeg8k/little_val/x')\n","train_loader = DataLoader(dataset=train_dataset, batch_size=4, shuffle=True,\n","        num_workers=6, pin_memory=False, drop_last=False)"],"metadata":{"id":"5aDuYfQBm342"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from tqdm import tqdm\n","from vit_pytorch import ViT, MAE\n","\n","v = ViT(\n","    image_size = (15,27),\n","    patch_size = (5, 9),\n","    num_classes = 13,\n","    dim = 1024,\n","    depth = 6,\n","    heads = 8,\n","    mlp_dim = 2048\n",")\n","\n","mae = MAE(\n","    encoder = v,\n","    masking_ratio = 0.75,   # the paper recommended 75% masked patches\n","    decoder_dim = 512,      # paper showed good results with just 512\n","    decoder_depth = 6       # anywhere from 1 to 8\n",")\n","\n","#mae\n","images = torch.randn(30, 3, 15, 27)\n","epoch_loss = 0\n","'''\n","for epoch in range(150):\n","  for i, data in enumerate(tqdm(train_loader), 0):\n","    _input = data[0].cuda()\n","    loss = mae(_input)\n","    loss.backward()\n","    epoch_loss+= loss\n","  torch.cuda.empty_cache()\n","  epoch_loss = 4*epoch_loss/train_dataset.__len__()\n","  print(\"Epoca: \", epoch, \"\\nPerdida: \", epoch_loss)\n","'''\n","for epoch in range(150):\n","  loss = mae(images)\n","  loss.backward()\n","  print(epoch)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"id":"6gdqWnrKjkIf","executionInfo":{"status":"error","timestamp":1713122048992,"user_tz":-120,"elapsed":5080,"user":{"displayName":"Ismael","userId":"03967480790510634870"}},"outputId":"e86f92f3-4849-46fd-8035-7b327513d2c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","1\n","2\n","3\n","4\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-54d3455b4e06>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m '''\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m   \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vit_pytorch/mae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mdecoder_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munmasked_indices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munmasked_decoder_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mdecoder_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked_indices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mdecoded_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# splice out the mask tokens and project to pixel values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vit_pytorch/vit.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mff\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vit_pytorch/vit.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import torch\n","from tqdm import tqdm\n","from vit_pytorch.vit_3d import ViT\n","\n","v = ViT(\n","    image_size = (12,20),          # image size\n","    frames = 1,               # number of frames\n","    image_patch_size = (3,5),     # image patch size\n","    frame_patch_size = 1,      # frame patch size\n","    num_classes = 13,\n","    dim = 1024,\n","    depth = 6,\n","    heads = 8,\n","    mlp_dim = 2048,\n","    dropout = 0.1,\n","    emb_dropout = 0.1\n",")\n","\n","video = torch.randn(30, 512, 1, 12, 20) # (batch, channels, frames, height, width)\n","\n","preds = v(video)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"id":"j1F656IOppxJ","executionInfo":{"status":"error","timestamp":1713116007076,"user_tz":-120,"elapsed":8019,"user":{"displayName":"Ismael","userId":"03967480790510634870"}},"outputId":"d3a130f0-3efd-46c8-dca9-51d7b898b703"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Given normalized_shape=[45], expected input with shape [*, 45], but got input of size[30, 16, 7680]","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-748b58ff43de>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mvideo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch, channels, frames, height, width)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vit_pytorch/vit_3d.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, video)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_patch_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         return F.layer_norm(\n\u001b[0m\u001b[1;32m    202\u001b[0m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2544\u001b[0m             \u001b[0mlayer_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2545\u001b[0m         )\n\u001b[0;32m-> 2546\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Given normalized_shape=[45], expected input with shape [*, 45], but got input of size[30, 16, 7680]"]}]},{"cell_type":"code","source":["import torch\n","import h5py\n","\n","with h5py.File('/content/drive/MyDrive/TFG/Parte2/DSSL/simsiam_hyperKvir/logs/resnet50/feature_maps_light/feature_map_00003.pt', 'r') as hf:\n","          img = torch.tensor(hf['feature_map_00003.pt'][:])\n","img.shape"],"metadata":{"id":"xUVgIY4E3y7o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713897649693,"user_tz":-120,"elapsed":2559,"user":{"displayName":"Ismael","userId":"03967480790510634870"}},"outputId":"b921a7d2-5045-4806-9e59-86bd8db70d15"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([512, 16, 32])"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["print(fm.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RiM8ExTG4UH1","executionInfo":{"status":"ok","timestamp":1713538950664,"user_tz":-120,"elapsed":239,"user":{"displayName":"Ismael","userId":"03967480790510634870"}},"outputId":"6bd4a960-e317-436e-e756-abc6dea1385d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2048, 16, 32])\n"]}]},{"cell_type":"code","source":["import os\n","DIR = '/content/drive/MyDrive/TFG/Parte2/DSSL/simsiam_hyperKvir/logs/resnet50/feature_maps_light'\n","print(len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wbtUZ6KIIOoF","executionInfo":{"status":"ok","timestamp":1713869100710,"user_tz":-120,"elapsed":49809,"user":{"displayName":"Ismael","userId":"03967480790510634870"}},"outputId":"03a26692-5be2-4c17-fb58-b9766fb08068"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["24010\n"]}]},{"cell_type":"code","source":["hey = torch.load('/content/drive/MyDrive/TFG/Parte2/DSSL/simsiam_hyperKvir/logs/resnet50/checkpoint_latest.pth.tar', map_location=torch.device('cpu'))\n","print(hey.keys())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8NW9Bp-rlhho","executionInfo":{"status":"ok","timestamp":1713888559042,"user_tz":-120,"elapsed":1916,"user":{"displayName":"Ismael","userId":"03967480790510634870"}},"outputId":"5d4580c0-5582-47ea-fa98-34e88124154a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["dict_keys(['epoch', 'arch', 'state_dict', 'optimizer'])\n"]}]},{"cell_type":"code","source":["claves = hey.keys()\n","features = [x for x in hey['state_dict'].keys() if x.split('.')[0]=='features']\n","print(features)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PQmp2c2otqx-","executionInfo":{"status":"ok","timestamp":1713889138780,"user_tz":-120,"elapsed":6,"user":{"displayName":"Ismael","userId":"03967480790510634870"}},"outputId":"a807d2aa-077e-4191-8135-a7528d9cb551"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['features.0.weight', 'features.1.weight', 'features.1.bias', 'features.1.running_mean', 'features.1.running_var', 'features.1.num_batches_tracked', 'features.4.0.conv1.weight', 'features.4.0.bn1.weight', 'features.4.0.bn1.bias', 'features.4.0.bn1.running_mean', 'features.4.0.bn1.running_var', 'features.4.0.bn1.num_batches_tracked', 'features.4.0.conv2.weight', 'features.4.0.bn2.weight', 'features.4.0.bn2.bias', 'features.4.0.bn2.running_mean', 'features.4.0.bn2.running_var', 'features.4.0.bn2.num_batches_tracked', 'features.4.0.conv3.weight', 'features.4.0.bn3.weight', 'features.4.0.bn3.bias', 'features.4.0.bn3.running_mean', 'features.4.0.bn3.running_var', 'features.4.0.bn3.num_batches_tracked', 'features.4.0.downsample.0.weight', 'features.4.0.downsample.1.weight', 'features.4.0.downsample.1.bias', 'features.4.0.downsample.1.running_mean', 'features.4.0.downsample.1.running_var', 'features.4.0.downsample.1.num_batches_tracked', 'features.4.1.conv1.weight', 'features.4.1.bn1.weight', 'features.4.1.bn1.bias', 'features.4.1.bn1.running_mean', 'features.4.1.bn1.running_var', 'features.4.1.bn1.num_batches_tracked', 'features.4.1.conv2.weight', 'features.4.1.bn2.weight', 'features.4.1.bn2.bias', 'features.4.1.bn2.running_mean', 'features.4.1.bn2.running_var', 'features.4.1.bn2.num_batches_tracked', 'features.4.1.conv3.weight', 'features.4.1.bn3.weight', 'features.4.1.bn3.bias', 'features.4.1.bn3.running_mean', 'features.4.1.bn3.running_var', 'features.4.1.bn3.num_batches_tracked', 'features.4.2.conv1.weight', 'features.4.2.bn1.weight', 'features.4.2.bn1.bias', 'features.4.2.bn1.running_mean', 'features.4.2.bn1.running_var', 'features.4.2.bn1.num_batches_tracked', 'features.4.2.conv2.weight', 'features.4.2.bn2.weight', 'features.4.2.bn2.bias', 'features.4.2.bn2.running_mean', 'features.4.2.bn2.running_var', 'features.4.2.bn2.num_batches_tracked', 'features.4.2.conv3.weight', 'features.4.2.bn3.weight', 'features.4.2.bn3.bias', 'features.4.2.bn3.running_mean', 'features.4.2.bn3.running_var', 'features.4.2.bn3.num_batches_tracked', 'features.5.0.conv1.weight', 'features.5.0.bn1.weight', 'features.5.0.bn1.bias', 'features.5.0.bn1.running_mean', 'features.5.0.bn1.running_var', 'features.5.0.bn1.num_batches_tracked', 'features.5.0.conv2.weight', 'features.5.0.bn2.weight', 'features.5.0.bn2.bias', 'features.5.0.bn2.running_mean', 'features.5.0.bn2.running_var', 'features.5.0.bn2.num_batches_tracked', 'features.5.0.conv3.weight', 'features.5.0.bn3.weight', 'features.5.0.bn3.bias', 'features.5.0.bn3.running_mean', 'features.5.0.bn3.running_var', 'features.5.0.bn3.num_batches_tracked', 'features.5.0.downsample.0.weight', 'features.5.0.downsample.1.weight', 'features.5.0.downsample.1.bias', 'features.5.0.downsample.1.running_mean', 'features.5.0.downsample.1.running_var', 'features.5.0.downsample.1.num_batches_tracked', 'features.5.1.conv1.weight', 'features.5.1.bn1.weight', 'features.5.1.bn1.bias', 'features.5.1.bn1.running_mean', 'features.5.1.bn1.running_var', 'features.5.1.bn1.num_batches_tracked', 'features.5.1.conv2.weight', 'features.5.1.bn2.weight', 'features.5.1.bn2.bias', 'features.5.1.bn2.running_mean', 'features.5.1.bn2.running_var', 'features.5.1.bn2.num_batches_tracked', 'features.5.1.conv3.weight', 'features.5.1.bn3.weight', 'features.5.1.bn3.bias', 'features.5.1.bn3.running_mean', 'features.5.1.bn3.running_var', 'features.5.1.bn3.num_batches_tracked', 'features.5.2.conv1.weight', 'features.5.2.bn1.weight', 'features.5.2.bn1.bias', 'features.5.2.bn1.running_mean', 'features.5.2.bn1.running_var', 'features.5.2.bn1.num_batches_tracked', 'features.5.2.conv2.weight', 'features.5.2.bn2.weight', 'features.5.2.bn2.bias', 'features.5.2.bn2.running_mean', 'features.5.2.bn2.running_var', 'features.5.2.bn2.num_batches_tracked', 'features.5.2.conv3.weight', 'features.5.2.bn3.weight', 'features.5.2.bn3.bias', 'features.5.2.bn3.running_mean', 'features.5.2.bn3.running_var', 'features.5.2.bn3.num_batches_tracked', 'features.5.3.conv1.weight', 'features.5.3.bn1.weight', 'features.5.3.bn1.bias', 'features.5.3.bn1.running_mean', 'features.5.3.bn1.running_var', 'features.5.3.bn1.num_batches_tracked', 'features.5.3.conv2.weight', 'features.5.3.bn2.weight', 'features.5.3.bn2.bias', 'features.5.3.bn2.running_mean', 'features.5.3.bn2.running_var', 'features.5.3.bn2.num_batches_tracked', 'features.5.3.conv3.weight', 'features.5.3.bn3.weight', 'features.5.3.bn3.bias', 'features.5.3.bn3.running_mean', 'features.5.3.bn3.running_var', 'features.5.3.bn3.num_batches_tracked', 'features.6.0.conv1.weight', 'features.6.0.bn1.weight', 'features.6.0.bn1.bias', 'features.6.0.bn1.running_mean', 'features.6.0.bn1.running_var', 'features.6.0.bn1.num_batches_tracked', 'features.6.0.conv2.weight', 'features.6.0.bn2.weight', 'features.6.0.bn2.bias', 'features.6.0.bn2.running_mean', 'features.6.0.bn2.running_var', 'features.6.0.bn2.num_batches_tracked', 'features.6.0.conv3.weight', 'features.6.0.bn3.weight', 'features.6.0.bn3.bias', 'features.6.0.bn3.running_mean', 'features.6.0.bn3.running_var', 'features.6.0.bn3.num_batches_tracked', 'features.6.0.downsample.0.weight', 'features.6.0.downsample.1.weight', 'features.6.0.downsample.1.bias', 'features.6.0.downsample.1.running_mean', 'features.6.0.downsample.1.running_var', 'features.6.0.downsample.1.num_batches_tracked', 'features.6.1.conv1.weight', 'features.6.1.bn1.weight', 'features.6.1.bn1.bias', 'features.6.1.bn1.running_mean', 'features.6.1.bn1.running_var', 'features.6.1.bn1.num_batches_tracked', 'features.6.1.conv2.weight', 'features.6.1.bn2.weight', 'features.6.1.bn2.bias', 'features.6.1.bn2.running_mean', 'features.6.1.bn2.running_var', 'features.6.1.bn2.num_batches_tracked', 'features.6.1.conv3.weight', 'features.6.1.bn3.weight', 'features.6.1.bn3.bias', 'features.6.1.bn3.running_mean', 'features.6.1.bn3.running_var', 'features.6.1.bn3.num_batches_tracked', 'features.6.2.conv1.weight', 'features.6.2.bn1.weight', 'features.6.2.bn1.bias', 'features.6.2.bn1.running_mean', 'features.6.2.bn1.running_var', 'features.6.2.bn1.num_batches_tracked', 'features.6.2.conv2.weight', 'features.6.2.bn2.weight', 'features.6.2.bn2.bias', 'features.6.2.bn2.running_mean', 'features.6.2.bn2.running_var', 'features.6.2.bn2.num_batches_tracked', 'features.6.2.conv3.weight', 'features.6.2.bn3.weight', 'features.6.2.bn3.bias', 'features.6.2.bn3.running_mean', 'features.6.2.bn3.running_var', 'features.6.2.bn3.num_batches_tracked', 'features.6.3.conv1.weight', 'features.6.3.bn1.weight', 'features.6.3.bn1.bias', 'features.6.3.bn1.running_mean', 'features.6.3.bn1.running_var', 'features.6.3.bn1.num_batches_tracked', 'features.6.3.conv2.weight', 'features.6.3.bn2.weight', 'features.6.3.bn2.bias', 'features.6.3.bn2.running_mean', 'features.6.3.bn2.running_var', 'features.6.3.bn2.num_batches_tracked', 'features.6.3.conv3.weight', 'features.6.3.bn3.weight', 'features.6.3.bn3.bias', 'features.6.3.bn3.running_mean', 'features.6.3.bn3.running_var', 'features.6.3.bn3.num_batches_tracked', 'features.6.4.conv1.weight', 'features.6.4.bn1.weight', 'features.6.4.bn1.bias', 'features.6.4.bn1.running_mean', 'features.6.4.bn1.running_var', 'features.6.4.bn1.num_batches_tracked', 'features.6.4.conv2.weight', 'features.6.4.bn2.weight', 'features.6.4.bn2.bias', 'features.6.4.bn2.running_mean', 'features.6.4.bn2.running_var', 'features.6.4.bn2.num_batches_tracked', 'features.6.4.conv3.weight', 'features.6.4.bn3.weight', 'features.6.4.bn3.bias', 'features.6.4.bn3.running_mean', 'features.6.4.bn3.running_var', 'features.6.4.bn3.num_batches_tracked', 'features.6.5.conv1.weight', 'features.6.5.bn1.weight', 'features.6.5.bn1.bias', 'features.6.5.bn1.running_mean', 'features.6.5.bn1.running_var', 'features.6.5.bn1.num_batches_tracked', 'features.6.5.conv2.weight', 'features.6.5.bn2.weight', 'features.6.5.bn2.bias', 'features.6.5.bn2.running_mean', 'features.6.5.bn2.running_var', 'features.6.5.bn2.num_batches_tracked', 'features.6.5.conv3.weight', 'features.6.5.bn3.weight', 'features.6.5.bn3.bias', 'features.6.5.bn3.running_mean', 'features.6.5.bn3.running_var', 'features.6.5.bn3.num_batches_tracked', 'features.7.0.conv1.weight', 'features.7.0.bn1.weight', 'features.7.0.bn1.bias', 'features.7.0.bn1.running_mean', 'features.7.0.bn1.running_var', 'features.7.0.bn1.num_batches_tracked', 'features.7.0.conv2.weight', 'features.7.0.bn2.weight', 'features.7.0.bn2.bias', 'features.7.0.bn2.running_mean', 'features.7.0.bn2.running_var', 'features.7.0.bn2.num_batches_tracked', 'features.7.0.conv3.weight', 'features.7.0.bn3.weight', 'features.7.0.bn3.bias', 'features.7.0.bn3.running_mean', 'features.7.0.bn3.running_var', 'features.7.0.bn3.num_batches_tracked', 'features.7.0.downsample.0.weight', 'features.7.0.downsample.1.weight', 'features.7.0.downsample.1.bias', 'features.7.0.downsample.1.running_mean', 'features.7.0.downsample.1.running_var', 'features.7.0.downsample.1.num_batches_tracked', 'features.7.1.conv1.weight', 'features.7.1.bn1.weight', 'features.7.1.bn1.bias', 'features.7.1.bn1.running_mean', 'features.7.1.bn1.running_var', 'features.7.1.bn1.num_batches_tracked', 'features.7.1.conv2.weight', 'features.7.1.bn2.weight', 'features.7.1.bn2.bias', 'features.7.1.bn2.running_mean', 'features.7.1.bn2.running_var', 'features.7.1.bn2.num_batches_tracked', 'features.7.1.conv3.weight', 'features.7.1.bn3.weight', 'features.7.1.bn3.bias', 'features.7.1.bn3.running_mean', 'features.7.1.bn3.running_var', 'features.7.1.bn3.num_batches_tracked', 'features.7.2.conv1.weight', 'features.7.2.bn1.weight', 'features.7.2.bn1.bias', 'features.7.2.bn1.running_mean', 'features.7.2.bn1.running_var', 'features.7.2.bn1.num_batches_tracked', 'features.7.2.conv2.weight', 'features.7.2.bn2.weight', 'features.7.2.bn2.bias', 'features.7.2.bn2.running_mean', 'features.7.2.bn2.running_var', 'features.7.2.bn2.num_batches_tracked', 'features.7.2.conv3.weight', 'features.7.2.bn3.weight', 'features.7.2.bn3.bias', 'features.7.2.bn3.running_mean', 'features.7.2.bn3.running_var', 'features.7.2.bn3.num_batches_tracked']\n"]}]},{"cell_type":"code","source":["features_keys = [x for x in features if not (x.startswith('features.7.2.conv3') or x.startswith('features.7.2.bn3'))]\n","state_dict_filtered = {k: v for k, v in hey['state_dict'].items() if k in features_keys}\n","hey['state_dict'] = state_dict_filtered\n","print(hey['state_dict'].keys())\n","print(hey.keys())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i9lfyU68v0d0","executionInfo":{"status":"ok","timestamp":1713889744497,"user_tz":-120,"elapsed":211,"user":{"displayName":"Ismael","userId":"03967480790510634870"}},"outputId":"dbe9d1d0-8204-48f5-88b8-a05530345f85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["dict_keys(['features.0.weight', 'features.1.weight', 'features.1.bias', 'features.1.running_mean', 'features.1.running_var', 'features.1.num_batches_tracked', 'features.4.0.conv1.weight', 'features.4.0.bn1.weight', 'features.4.0.bn1.bias', 'features.4.0.bn1.running_mean', 'features.4.0.bn1.running_var', 'features.4.0.bn1.num_batches_tracked', 'features.4.0.conv2.weight', 'features.4.0.bn2.weight', 'features.4.0.bn2.bias', 'features.4.0.bn2.running_mean', 'features.4.0.bn2.running_var', 'features.4.0.bn2.num_batches_tracked', 'features.4.0.conv3.weight', 'features.4.0.bn3.weight', 'features.4.0.bn3.bias', 'features.4.0.bn3.running_mean', 'features.4.0.bn3.running_var', 'features.4.0.bn3.num_batches_tracked', 'features.4.0.downsample.0.weight', 'features.4.0.downsample.1.weight', 'features.4.0.downsample.1.bias', 'features.4.0.downsample.1.running_mean', 'features.4.0.downsample.1.running_var', 'features.4.0.downsample.1.num_batches_tracked', 'features.4.1.conv1.weight', 'features.4.1.bn1.weight', 'features.4.1.bn1.bias', 'features.4.1.bn1.running_mean', 'features.4.1.bn1.running_var', 'features.4.1.bn1.num_batches_tracked', 'features.4.1.conv2.weight', 'features.4.1.bn2.weight', 'features.4.1.bn2.bias', 'features.4.1.bn2.running_mean', 'features.4.1.bn2.running_var', 'features.4.1.bn2.num_batches_tracked', 'features.4.1.conv3.weight', 'features.4.1.bn3.weight', 'features.4.1.bn3.bias', 'features.4.1.bn3.running_mean', 'features.4.1.bn3.running_var', 'features.4.1.bn3.num_batches_tracked', 'features.4.2.conv1.weight', 'features.4.2.bn1.weight', 'features.4.2.bn1.bias', 'features.4.2.bn1.running_mean', 'features.4.2.bn1.running_var', 'features.4.2.bn1.num_batches_tracked', 'features.4.2.conv2.weight', 'features.4.2.bn2.weight', 'features.4.2.bn2.bias', 'features.4.2.bn2.running_mean', 'features.4.2.bn2.running_var', 'features.4.2.bn2.num_batches_tracked', 'features.4.2.conv3.weight', 'features.4.2.bn3.weight', 'features.4.2.bn3.bias', 'features.4.2.bn3.running_mean', 'features.4.2.bn3.running_var', 'features.4.2.bn3.num_batches_tracked', 'features.5.0.conv1.weight', 'features.5.0.bn1.weight', 'features.5.0.bn1.bias', 'features.5.0.bn1.running_mean', 'features.5.0.bn1.running_var', 'features.5.0.bn1.num_batches_tracked', 'features.5.0.conv2.weight', 'features.5.0.bn2.weight', 'features.5.0.bn2.bias', 'features.5.0.bn2.running_mean', 'features.5.0.bn2.running_var', 'features.5.0.bn2.num_batches_tracked', 'features.5.0.conv3.weight', 'features.5.0.bn3.weight', 'features.5.0.bn3.bias', 'features.5.0.bn3.running_mean', 'features.5.0.bn3.running_var', 'features.5.0.bn3.num_batches_tracked', 'features.5.0.downsample.0.weight', 'features.5.0.downsample.1.weight', 'features.5.0.downsample.1.bias', 'features.5.0.downsample.1.running_mean', 'features.5.0.downsample.1.running_var', 'features.5.0.downsample.1.num_batches_tracked', 'features.5.1.conv1.weight', 'features.5.1.bn1.weight', 'features.5.1.bn1.bias', 'features.5.1.bn1.running_mean', 'features.5.1.bn1.running_var', 'features.5.1.bn1.num_batches_tracked', 'features.5.1.conv2.weight', 'features.5.1.bn2.weight', 'features.5.1.bn2.bias', 'features.5.1.bn2.running_mean', 'features.5.1.bn2.running_var', 'features.5.1.bn2.num_batches_tracked', 'features.5.1.conv3.weight', 'features.5.1.bn3.weight', 'features.5.1.bn3.bias', 'features.5.1.bn3.running_mean', 'features.5.1.bn3.running_var', 'features.5.1.bn3.num_batches_tracked', 'features.5.2.conv1.weight', 'features.5.2.bn1.weight', 'features.5.2.bn1.bias', 'features.5.2.bn1.running_mean', 'features.5.2.bn1.running_var', 'features.5.2.bn1.num_batches_tracked', 'features.5.2.conv2.weight', 'features.5.2.bn2.weight', 'features.5.2.bn2.bias', 'features.5.2.bn2.running_mean', 'features.5.2.bn2.running_var', 'features.5.2.bn2.num_batches_tracked', 'features.5.2.conv3.weight', 'features.5.2.bn3.weight', 'features.5.2.bn3.bias', 'features.5.2.bn3.running_mean', 'features.5.2.bn3.running_var', 'features.5.2.bn3.num_batches_tracked', 'features.5.3.conv1.weight', 'features.5.3.bn1.weight', 'features.5.3.bn1.bias', 'features.5.3.bn1.running_mean', 'features.5.3.bn1.running_var', 'features.5.3.bn1.num_batches_tracked', 'features.5.3.conv2.weight', 'features.5.3.bn2.weight', 'features.5.3.bn2.bias', 'features.5.3.bn2.running_mean', 'features.5.3.bn2.running_var', 'features.5.3.bn2.num_batches_tracked', 'features.5.3.conv3.weight', 'features.5.3.bn3.weight', 'features.5.3.bn3.bias', 'features.5.3.bn3.running_mean', 'features.5.3.bn3.running_var', 'features.5.3.bn3.num_batches_tracked', 'features.6.0.conv1.weight', 'features.6.0.bn1.weight', 'features.6.0.bn1.bias', 'features.6.0.bn1.running_mean', 'features.6.0.bn1.running_var', 'features.6.0.bn1.num_batches_tracked', 'features.6.0.conv2.weight', 'features.6.0.bn2.weight', 'features.6.0.bn2.bias', 'features.6.0.bn2.running_mean', 'features.6.0.bn2.running_var', 'features.6.0.bn2.num_batches_tracked', 'features.6.0.conv3.weight', 'features.6.0.bn3.weight', 'features.6.0.bn3.bias', 'features.6.0.bn3.running_mean', 'features.6.0.bn3.running_var', 'features.6.0.bn3.num_batches_tracked', 'features.6.0.downsample.0.weight', 'features.6.0.downsample.1.weight', 'features.6.0.downsample.1.bias', 'features.6.0.downsample.1.running_mean', 'features.6.0.downsample.1.running_var', 'features.6.0.downsample.1.num_batches_tracked', 'features.6.1.conv1.weight', 'features.6.1.bn1.weight', 'features.6.1.bn1.bias', 'features.6.1.bn1.running_mean', 'features.6.1.bn1.running_var', 'features.6.1.bn1.num_batches_tracked', 'features.6.1.conv2.weight', 'features.6.1.bn2.weight', 'features.6.1.bn2.bias', 'features.6.1.bn2.running_mean', 'features.6.1.bn2.running_var', 'features.6.1.bn2.num_batches_tracked', 'features.6.1.conv3.weight', 'features.6.1.bn3.weight', 'features.6.1.bn3.bias', 'features.6.1.bn3.running_mean', 'features.6.1.bn3.running_var', 'features.6.1.bn3.num_batches_tracked', 'features.6.2.conv1.weight', 'features.6.2.bn1.weight', 'features.6.2.bn1.bias', 'features.6.2.bn1.running_mean', 'features.6.2.bn1.running_var', 'features.6.2.bn1.num_batches_tracked', 'features.6.2.conv2.weight', 'features.6.2.bn2.weight', 'features.6.2.bn2.bias', 'features.6.2.bn2.running_mean', 'features.6.2.bn2.running_var', 'features.6.2.bn2.num_batches_tracked', 'features.6.2.conv3.weight', 'features.6.2.bn3.weight', 'features.6.2.bn3.bias', 'features.6.2.bn3.running_mean', 'features.6.2.bn3.running_var', 'features.6.2.bn3.num_batches_tracked', 'features.6.3.conv1.weight', 'features.6.3.bn1.weight', 'features.6.3.bn1.bias', 'features.6.3.bn1.running_mean', 'features.6.3.bn1.running_var', 'features.6.3.bn1.num_batches_tracked', 'features.6.3.conv2.weight', 'features.6.3.bn2.weight', 'features.6.3.bn2.bias', 'features.6.3.bn2.running_mean', 'features.6.3.bn2.running_var', 'features.6.3.bn2.num_batches_tracked', 'features.6.3.conv3.weight', 'features.6.3.bn3.weight', 'features.6.3.bn3.bias', 'features.6.3.bn3.running_mean', 'features.6.3.bn3.running_var', 'features.6.3.bn3.num_batches_tracked', 'features.6.4.conv1.weight', 'features.6.4.bn1.weight', 'features.6.4.bn1.bias', 'features.6.4.bn1.running_mean', 'features.6.4.bn1.running_var', 'features.6.4.bn1.num_batches_tracked', 'features.6.4.conv2.weight', 'features.6.4.bn2.weight', 'features.6.4.bn2.bias', 'features.6.4.bn2.running_mean', 'features.6.4.bn2.running_var', 'features.6.4.bn2.num_batches_tracked', 'features.6.4.conv3.weight', 'features.6.4.bn3.weight', 'features.6.4.bn3.bias', 'features.6.4.bn3.running_mean', 'features.6.4.bn3.running_var', 'features.6.4.bn3.num_batches_tracked', 'features.6.5.conv1.weight', 'features.6.5.bn1.weight', 'features.6.5.bn1.bias', 'features.6.5.bn1.running_mean', 'features.6.5.bn1.running_var', 'features.6.5.bn1.num_batches_tracked', 'features.6.5.conv2.weight', 'features.6.5.bn2.weight', 'features.6.5.bn2.bias', 'features.6.5.bn2.running_mean', 'features.6.5.bn2.running_var', 'features.6.5.bn2.num_batches_tracked', 'features.6.5.conv3.weight', 'features.6.5.bn3.weight', 'features.6.5.bn3.bias', 'features.6.5.bn3.running_mean', 'features.6.5.bn3.running_var', 'features.6.5.bn3.num_batches_tracked', 'features.7.0.conv1.weight', 'features.7.0.bn1.weight', 'features.7.0.bn1.bias', 'features.7.0.bn1.running_mean', 'features.7.0.bn1.running_var', 'features.7.0.bn1.num_batches_tracked', 'features.7.0.conv2.weight', 'features.7.0.bn2.weight', 'features.7.0.bn2.bias', 'features.7.0.bn2.running_mean', 'features.7.0.bn2.running_var', 'features.7.0.bn2.num_batches_tracked', 'features.7.0.conv3.weight', 'features.7.0.bn3.weight', 'features.7.0.bn3.bias', 'features.7.0.bn3.running_mean', 'features.7.0.bn3.running_var', 'features.7.0.bn3.num_batches_tracked', 'features.7.0.downsample.0.weight', 'features.7.0.downsample.1.weight', 'features.7.0.downsample.1.bias', 'features.7.0.downsample.1.running_mean', 'features.7.0.downsample.1.running_var', 'features.7.0.downsample.1.num_batches_tracked', 'features.7.1.conv1.weight', 'features.7.1.bn1.weight', 'features.7.1.bn1.bias', 'features.7.1.bn1.running_mean', 'features.7.1.bn1.running_var', 'features.7.1.bn1.num_batches_tracked', 'features.7.1.conv2.weight', 'features.7.1.bn2.weight', 'features.7.1.bn2.bias', 'features.7.1.bn2.running_mean', 'features.7.1.bn2.running_var', 'features.7.1.bn2.num_batches_tracked', 'features.7.1.conv3.weight', 'features.7.1.bn3.weight', 'features.7.1.bn3.bias', 'features.7.1.bn3.running_mean', 'features.7.1.bn3.running_var', 'features.7.1.bn3.num_batches_tracked', 'features.7.2.conv1.weight', 'features.7.2.bn1.weight', 'features.7.2.bn1.bias', 'features.7.2.bn1.running_mean', 'features.7.2.bn1.running_var', 'features.7.2.bn1.num_batches_tracked', 'features.7.2.conv2.weight', 'features.7.2.bn2.weight', 'features.7.2.bn2.bias', 'features.7.2.bn2.running_mean', 'features.7.2.bn2.running_var', 'features.7.2.bn2.num_batches_tracked'])\n","dict_keys(['epoch', 'arch', 'state_dict', 'optimizer'])\n"]}]},{"cell_type":"code","source":["print(hey['state_dict']['features.0.weight'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wMvyroCAGeql","executionInfo":{"status":"ok","timestamp":1713894998102,"user_tz":-120,"elapsed":293,"user":{"displayName":"Ismael","userId":"03967480790510634870"}},"outputId":"128869e4-9ef8-44e4-bc12-a7ae2f1d69d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[[ 4.0960e-02, -4.5461e-02, -4.3192e-02,  ..., -1.1232e-02,\n","           -1.7687e-02, -3.7987e-02],\n","          [ 1.4980e-02, -2.7269e-02,  2.2831e-02,  ..., -9.6498e-03,\n","            5.1178e-03, -2.9816e-02],\n","          [ 2.1066e-02,  4.2191e-03,  2.0848e-03,  ...,  1.2058e-02,\n","            1.6102e-02,  1.2281e-02],\n","          ...,\n","          [ 1.1706e-02, -5.9333e-03,  1.1491e-02,  ...,  2.1931e-02,\n","           -1.3246e-03, -3.5314e-02],\n","          [-5.9471e-03, -6.2125e-02, -3.1443e-02,  ..., -4.7594e-03,\n","           -4.8082e-02, -6.7737e-02],\n","          [-1.2331e-02, -5.6960e-02, -2.9785e-02,  ..., -4.4195e-02,\n","           -6.0342e-02, -2.4785e-02]],\n","\n","         [[ 1.3895e-02, -1.8490e-02, -2.5026e-02,  ..., -2.5087e-02,\n","           -5.6475e-03,  4.3826e-03],\n","          [ 7.0338e-03, -1.9813e-02, -5.7606e-03,  ..., -1.5327e-02,\n","           -1.0803e-02, -6.1032e-03],\n","          [ 5.2435e-03, -1.9754e-02,  1.3894e-02,  ...,  7.6334e-04,\n","            1.6362e-02,  5.3395e-03],\n","          ...,\n","          [ 6.4315e-03, -1.4660e-02,  8.7336e-03,  ...,  2.0008e-02,\n","            8.0041e-03, -3.8514e-02],\n","          [-3.6040e-03, -3.1246e-02, -7.5110e-03,  ..., -2.0647e-02,\n","           -2.7773e-02, -5.2751e-02],\n","          [-3.2817e-03, -5.5888e-02, -2.9342e-02,  ..., -3.4137e-02,\n","           -4.2201e-02, -4.4041e-02]],\n","\n","         [[ 3.3484e-02, -1.5266e-02,  1.0027e-02,  ..., -1.3880e-03,\n","            6.7963e-03,  9.6321e-03],\n","          [ 4.7761e-04, -2.1730e-02,  4.4201e-03,  ..., -8.0572e-03,\n","            7.4170e-03,  1.1476e-03],\n","          [-4.5331e-03, -9.7495e-03,  2.0702e-02,  ...,  2.1458e-02,\n","            1.1835e-02,  3.9874e-03],\n","          ...,\n","          [ 1.4857e-03, -1.3499e-02,  2.2939e-02,  ...,  2.0876e-02,\n","            6.5853e-03, -2.6338e-02],\n","          [-8.5848e-03, -1.6083e-02, -3.8474e-03,  ..., -1.8234e-02,\n","           -4.0418e-02, -5.4937e-02],\n","          [-4.4484e-03, -3.1029e-02, -2.8991e-02,  ..., -4.2871e-02,\n","           -3.4109e-02, -5.0793e-02]]],\n","\n","\n","        [[[ 4.2074e-02,  1.7353e-02,  3.2356e-02,  ...,  1.2960e-02,\n","            3.0610e-02,  9.4083e-03],\n","          [ 1.3067e-02,  1.1432e-02,  1.6729e-02,  ...,  4.3338e-03,\n","           -9.4335e-03, -1.4944e-03],\n","          [ 3.0520e-02, -6.0891e-04,  9.9141e-04,  ..., -8.5585e-04,\n","           -1.7227e-02, -1.3423e-02],\n","          ...,\n","          [-6.5320e-03,  2.4991e-03, -1.1907e-02,  ..., -2.9595e-03,\n","           -3.1096e-02, -2.9529e-02],\n","          [-2.2200e-02, -1.8339e-02, -1.1918e-02,  ..., -1.0207e-02,\n","           -1.0771e-02, -3.7763e-02],\n","          [-7.9510e-04, -1.1529e-02, -1.4708e-02,  ..., -2.3324e-02,\n","           -5.1431e-02, -4.8831e-02]],\n","\n","         [[ 3.8233e-02,  8.7989e-03,  2.5322e-02,  ...,  8.1526e-03,\n","            3.6488e-02,  4.3937e-02],\n","          [ 2.1565e-02,  2.0452e-02,  2.1340e-02,  ...,  8.3110e-03,\n","            3.0054e-02,  3.5619e-02],\n","          [ 4.2016e-02,  1.7399e-02,  4.2794e-02,  ...,  3.5478e-02,\n","            4.5155e-02,  4.5419e-02],\n","          ...,\n","          [ 5.8610e-02,  4.0795e-02,  3.9254e-02,  ...,  3.4856e-02,\n","            4.0734e-02,  9.0350e-03],\n","          [ 5.0456e-02,  3.8546e-02,  6.2875e-02,  ...,  4.0004e-02,\n","            2.8001e-02,  1.0318e-02],\n","          [ 5.6517e-02,  5.8344e-02,  5.8423e-02,  ...,  1.0939e-02,\n","           -1.7061e-02, -2.3414e-02]],\n","\n","         [[ 3.4932e-02, -4.1708e-03,  2.1353e-02,  ...,  2.4837e-03,\n","           -2.8251e-03,  8.4883e-03],\n","          [ 1.1175e-02, -1.0545e-02,  4.7560e-03,  ..., -2.5723e-02,\n","           -2.7199e-02,  1.1076e-02],\n","          [ 3.8681e-03, -8.2300e-03, -2.0061e-03,  ..., -4.6083e-03,\n","           -6.5645e-03, -6.3005e-03],\n","          ...,\n","          [-1.7052e-02, -2.1901e-02, -3.0919e-02,  ..., -5.5103e-02,\n","           -5.8295e-02, -9.0890e-02],\n","          [-2.5432e-02, -4.1028e-02, -2.6691e-02,  ..., -6.7433e-02,\n","           -7.2313e-02, -1.0845e-01],\n","          [-1.2314e-02, -2.7179e-02, -3.2410e-02,  ..., -7.8966e-02,\n","           -1.1113e-01, -1.0291e-01]]],\n","\n","\n","        [[[ 1.1233e-02,  1.6596e-03,  9.4062e-03,  ...,  9.2977e-03,\n","           -6.1705e-03, -1.3442e-02],\n","          [ 1.7702e-02,  4.3631e-03, -1.1169e-03,  ...,  3.5316e-03,\n","           -1.5724e-03,  8.6923e-03],\n","          [ 1.4165e-02,  1.2225e-02,  6.3578e-03,  ...,  8.2357e-03,\n","           -1.1263e-02,  4.8884e-03],\n","          ...,\n","          [-1.0373e-02,  4.4369e-03,  1.0275e-03,  ..., -1.1009e-02,\n","            1.0622e-02, -1.1343e-02],\n","          [-9.2123e-03, -8.9702e-03,  1.1036e-02,  ...,  6.3839e-03,\n","            6.5655e-04,  8.0329e-03],\n","          [-1.5582e-03,  4.3834e-03,  8.7988e-03,  ...,  7.4337e-03,\n","            1.3796e-02,  8.0849e-03]],\n","\n","         [[ 7.1742e-03,  3.4907e-02,  3.8101e-02,  ...,  2.1400e-03,\n","            2.7118e-03, -5.7487e-03],\n","          [ 3.7520e-02,  4.4003e-02,  4.0675e-02,  ...,  1.0170e-02,\n","            3.3537e-03,  1.3953e-02],\n","          [ 1.6833e-02,  1.3452e-02,  2.8288e-02,  ...,  2.0967e-02,\n","            1.5238e-02, -4.3688e-03],\n","          ...,\n","          [ 8.5705e-03, -1.0282e-03,  1.5215e-02,  ...,  1.3975e-02,\n","            1.4585e-02,  1.6483e-02],\n","          [-3.7202e-03,  3.7860e-04,  6.0588e-03,  ...,  7.9919e-03,\n","            2.7819e-02,  2.8075e-02],\n","          [ 2.0018e-02,  2.5271e-02,  5.1568e-03,  ...,  2.3965e-02,\n","            2.3964e-02,  3.1951e-03]],\n","\n","         [[-1.4867e-03, -1.9640e-03,  1.6718e-02,  ..., -1.6915e-02,\n","           -1.3364e-02, -1.4416e-02],\n","          [ 1.5136e-02,  2.8291e-02,  1.5417e-02,  ..., -6.2909e-03,\n","           -1.6251e-02, -7.6626e-04],\n","          [ 4.9249e-03,  1.7144e-02, -1.1903e-02,  ...,  3.5643e-03,\n","           -3.2011e-03, -1.6771e-02],\n","          ...,\n","          [-1.8720e-02, -2.3227e-02, -1.7090e-02,  ...,  1.3640e-03,\n","            3.1448e-03, -9.3239e-03],\n","          [ 3.5232e-03, -1.2568e-02, -1.2048e-02,  ...,  1.0841e-02,\n","            1.7964e-02,  7.7392e-03],\n","          [-7.4624e-03,  1.3014e-02, -7.8157e-03,  ...,  1.8927e-02,\n","            5.4778e-03, -4.6524e-03]]],\n","\n","\n","        ...,\n","\n","\n","        [[[-1.3209e-02, -9.9881e-03,  6.9686e-03,  ...,  2.1595e-02,\n","            2.2848e-02,  1.5878e-02],\n","          [-5.3314e-03,  2.3982e-02,  3.1959e-02,  ...,  2.4305e-02,\n","            2.6371e-02,  3.1506e-02],\n","          [ 1.3262e-02,  2.7910e-02,  2.9253e-02,  ...,  2.6289e-02,\n","            2.7304e-02,  1.7238e-02],\n","          ...,\n","          [ 1.7118e-02, -1.7424e-03, -5.8082e-03,  ...,  3.6117e-03,\n","            2.5163e-02,  7.5505e-03],\n","          [ 1.5808e-03,  1.3346e-02,  1.5328e-02,  ..., -1.4426e-02,\n","           -5.1588e-03,  2.1885e-02],\n","          [ 1.3783e-02,  3.0413e-03,  6.9943e-03,  ...,  1.2828e-02,\n","            2.4401e-02,  3.5840e-02]],\n","\n","         [[ 5.4909e-03, -2.4827e-03, -1.2148e-03,  ...,  1.3188e-02,\n","           -4.5183e-05,  4.6741e-03],\n","          [ 9.7585e-04,  2.3586e-02,  1.0481e-02,  ...,  9.2958e-03,\n","            1.2346e-02,  2.3036e-02],\n","          [ 6.2437e-03, -5.8209e-04,  2.6516e-04,  ..., -8.9437e-03,\n","            1.5333e-03,  8.0239e-03],\n","          ...,\n","          [ 2.2055e-02,  1.9545e-02, -9.8800e-03,  ...,  2.5131e-03,\n","            8.1018e-03,  3.8445e-03],\n","          [ 1.1916e-02,  2.2936e-02, -2.5285e-03,  ..., -1.3273e-02,\n","            9.3658e-03, -1.9330e-03],\n","          [ 9.5056e-03,  2.7318e-03,  1.3739e-02,  ...,  1.7425e-02,\n","            1.8746e-02,  5.4325e-03]],\n","\n","         [[-1.7653e-02, -7.4674e-03, -1.9590e-02,  ..., -1.6654e-02,\n","           -1.8760e-02, -1.5139e-02],\n","          [-6.8234e-03,  8.0778e-03,  6.5628e-03,  ..., -4.0359e-04,\n","            3.1110e-03,  2.9015e-02],\n","          [-3.8610e-03, -6.6826e-03,  3.4936e-03,  ..., -1.1189e-02,\n","           -4.5627e-05, -8.4366e-03],\n","          ...,\n","          [-4.7051e-03,  7.1107e-04,  9.9321e-04,  ...,  4.7559e-03,\n","           -8.1620e-03,  1.4356e-02],\n","          [-2.4569e-03, -6.4145e-03, -5.8348e-03,  ..., -1.7244e-02,\n","           -9.4809e-04, -2.2659e-04],\n","          [-1.8165e-03,  4.1841e-03, -1.0156e-03,  ..., -1.1569e-02,\n","           -7.5400e-03, -6.7196e-03]]],\n","\n","\n","        [[[-2.1773e-02,  2.3515e-03,  2.0475e-02,  ...,  6.2849e-04,\n","            2.3797e-03,  2.1545e-02],\n","          [-3.1977e-02, -6.8777e-03,  1.7601e-03,  ...,  1.2423e-03,\n","            2.2751e-02,  1.6274e-02],\n","          [-2.9427e-02, -1.0675e-02,  3.8336e-04,  ...,  1.9628e-02,\n","            2.8442e-02,  2.9034e-02],\n","          ...,\n","          [-1.8818e-02, -2.4314e-02, -2.2771e-02,  ...,  2.9501e-02,\n","            4.0777e-02,  4.0476e-02],\n","          [-5.6496e-03, -1.7516e-02, -1.5402e-02,  ...,  1.7779e-02,\n","            4.0700e-02,  4.0795e-02],\n","          [-2.4451e-02, -1.2003e-02, -1.9149e-02,  ...,  2.2951e-02,\n","            3.0284e-02,  4.1556e-02]],\n","\n","         [[-5.6911e-02,  1.8830e-02,  1.2084e-02,  ..., -7.9868e-02,\n","            1.4990e-02,  6.5036e-02],\n","          [-8.7683e-03,  1.7138e-02, -3.5628e-02,  ..., -7.5802e-02,\n","            7.8420e-02,  1.1742e-01],\n","          [ 4.5769e-02,  1.4683e-02, -9.1727e-02,  ..., -6.6593e-02,\n","            1.3985e-01,  1.6588e-01],\n","          ...,\n","          [ 4.6054e-02, -9.9358e-03, -1.1994e-01,  ...,  3.8412e-02,\n","            2.0311e-01,  1.9301e-01],\n","          [ 2.4445e-02, -3.1141e-02, -1.0099e-01,  ...,  2.2195e-02,\n","            1.6456e-01,  1.9222e-01],\n","          [-4.9211e-02, -2.0527e-02, -5.4684e-02,  ...,  6.3655e-03,\n","            8.9607e-02,  1.2800e-01]],\n","\n","         [[-8.1218e-03,  6.2363e-02,  4.1800e-02,  ..., -6.3146e-02,\n","            1.1057e-02,  8.0770e-02],\n","          [ 1.4518e-02,  1.0146e-01, -5.0833e-03,  ..., -7.8891e-02,\n","            2.5281e-02,  9.2916e-02],\n","          [ 6.8240e-02,  1.0086e-01, -5.6876e-03,  ..., -9.1790e-02,\n","            5.5413e-02,  1.1275e-01],\n","          ...,\n","          [ 8.9441e-02,  8.5024e-02, -5.9320e-02,  ..., -9.3605e-02,\n","            6.8730e-02,  1.2197e-01],\n","          [ 7.1669e-02,  4.7334e-02, -5.0347e-02,  ..., -7.8591e-02,\n","            3.5080e-02,  1.2891e-01],\n","          [ 1.4901e-02,  2.0854e-02, -1.6696e-02,  ..., -4.3724e-02,\n","            2.0669e-02,  1.1148e-01]]],\n","\n","\n","        [[[-7.4144e-03,  2.8364e-03,  2.6923e-03,  ..., -8.3404e-03,\n","           -1.7763e-03,  4.8461e-03],\n","          [ 1.1592e-03, -2.6557e-03,  1.1188e-02,  ...,  6.9227e-03,\n","            2.0417e-03,  1.9606e-03],\n","          [ 3.3832e-04,  9.0880e-03,  2.2897e-02,  ...,  1.1195e-02,\n","            1.9750e-02,  2.4036e-02],\n","          ...,\n","          [-7.1729e-03,  1.5173e-02, -8.5484e-03,  ..., -4.7927e-03,\n","            1.0862e-02,  1.1851e-02],\n","          [ 4.6262e-03,  5.2258e-03,  1.2544e-02,  ..., -8.6737e-03,\n","            3.9390e-03,  6.1415e-03],\n","          [-1.2674e-03,  2.8972e-02,  2.3821e-02,  ...,  9.4020e-03,\n","           -4.3798e-03,  6.2049e-04]],\n","\n","         [[-1.5635e-03,  1.3861e-02, -5.1667e-03,  ..., -2.6506e-03,\n","            7.3433e-03,  2.6900e-03],\n","          [ 1.2190e-02,  3.0440e-02,  1.6868e-02,  ...,  1.2305e-02,\n","            1.2419e-02,  2.5749e-02],\n","          [ 1.9009e-02,  9.4845e-03,  8.7579e-03,  ...,  1.3506e-02,\n","            1.8883e-02,  2.4705e-02],\n","          ...,\n","          [-3.4625e-03,  2.3194e-04, -1.0792e-02,  ..., -3.8103e-04,\n","           -1.4508e-02,  1.1397e-02],\n","          [ 1.9194e-02,  1.9061e-02,  1.5033e-02,  ..., -4.8229e-03,\n","           -6.3657e-03, -2.3527e-03],\n","          [ 7.8226e-03,  1.0189e-02,  1.7083e-02,  ..., -7.7460e-03,\n","           -2.6617e-03,  1.7202e-02]],\n","\n","         [[-1.5752e-02, -3.2093e-03, -1.4719e-02,  ..., -1.8892e-03,\n","            2.8467e-03,  9.7055e-04],\n","          [ 2.0906e-02,  1.8380e-02,  1.5623e-02,  ...,  2.8231e-02,\n","            2.4170e-02,  3.3885e-02],\n","          [ 1.0935e-02,  2.4709e-02,  3.9131e-03,  ...,  1.2692e-02,\n","            2.7852e-02,  1.2879e-02],\n","          ...,\n","          [-1.8739e-03,  2.7893e-02,  4.1105e-03,  ..., -1.9655e-04,\n","           -1.1847e-02, -2.4869e-03],\n","          [ 1.5432e-02,  1.5891e-02,  3.7522e-03,  ...,  1.5750e-02,\n","           -7.4687e-03, -1.8151e-03],\n","          [ 1.3947e-02,  4.0651e-02,  2.4072e-02,  ...,  1.4142e-02,\n","            2.9139e-02,  2.8494e-02]]]])\n"]}]},{"cell_type":"code","source":["a = 'jamaica'\n","b = 'queso'\n","print(zip(a,b))\n","\n","for e, c in zip(a,b):\n","  print(e, c)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aF3OzqwpngVk","executionInfo":{"status":"ok","timestamp":1713819817393,"user_tz":-120,"elapsed":260,"user":{"displayName":"Ismael","userId":"03967480790510634870"}},"outputId":"3521c0d9-71d6-41ff-a160-be4b13ce30df"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<zip object at 0x7ca6f987e240>\n","j q\n","a u\n","m e\n","a s\n","i o\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","model = nn.Sequential(\n","          nn.Conv2d(1,20,5),\n","          nn.ReLU(),\n","          nn.Conv2d(20,64,5),\n","          nn.ReLU()\n","        )\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LKXggTyMR6IS","executionInfo":{"status":"ok","timestamp":1714653010828,"user_tz":-120,"elapsed":213,"user":{"displayName":"Ismael","userId":"03967480790510634870"}},"outputId":"79593b3c-afcf-4602-f061-932f4aa52bb5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequential(\n","  (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n","  (1): ReLU()\n","  (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n","  (3): ReLU()\n",")\n"]}]},{"cell_type":"code","source":["def conv3x3(in_planes, out_planes, stride=1):\n","    \"3x3 convolution with padding\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=1, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(Bottleneck, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, planes * Bottleneck.expansion, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * Bottleneck.expansion)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","class BottleneckLast(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(BottleneckLast, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        if residual.shape[1] == out.shape[1]:\n","            out += residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, depth):\n","        super(ResNet, self).__init__()\n","\n","        blocks = {18: BasicBlock, 34: BasicBlock, 50: Bottleneck, 101: Bottleneck, 152: Bottleneck, 200: Bottleneck}\n","        layers = {18: [2, 2, 2, 2], 34: [3, 4, 6, 3], 50: [3, 4, 6, 3], 101: [3, 4, 23, 3], 152: [3, 8, 36, 3],\n","                    200: [3, 24, 36, 3]}\n","        assert layers[depth], 'invalid detph for ResNet (depth should be one of 18, 34, 50, 101, 152, and 200)'\n","\n","        self.inplanes = 64\n","        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        self.layer1 = self._make_layer(blocks[depth], 64, layers[depth][0])\n","        self.layer2 = self._make_layer(blocks[depth], 128, layers[depth][1], stride=2)\n","        self.layer3 = self._make_layer(blocks[depth], 256, layers[depth][2], stride=2)\n","        self.layer4 = self._make_layer(BottleneckLast, 512, layers[depth][3], stride=2)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, math.sqrt(2. / n))\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","    def _make_layer(self, block, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, planes * block.expansion,\n","                          kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        if block == BottleneckLast:\n","            layers.append(Bottleneck(self.inplanes, planes, stride, downsample))\n","        else:\n","            layers.append(block(self.inplanes, planes, stride, downsample))\n","        self.inplanes = planes * block.expansion\n","        for i in range(1, blocks):\n","            if block == BottleneckLast and i == blocks -1:\n","                layers.append(block(self.inplanes, planes))\n","            else:\n","                layers.append(Bottleneck(self.inplanes, planes))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        return x\n","\n","\n","def resnet50():\n","    return ResNet(depth=50)\n","\n","\n","def resnet18():\n","    return ResNet(depth=18)"],"metadata":{"id":"QrycDzkjSQdI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import math\n","class FeatureGetter(nn.Module):\n","\n","    def __init__(self, backbone='resnet50', d=2048):\n","        super(FeatureGetter, self).__init__()\n","\n","        if backbone == 'resnet50':\n","            net = resnet50()\n","        elif backbone == 'resnet18':\n","            net = resnet18()\n","        else:\n","            raise NotImplementedError('Backbone model not implemented.')\n","\n","        self.features = nn.Sequential(*list(net.children()))\n","\n","        self.reset_parameters()\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","\n","        return x\n","\n","    def reset_parameters(self):\n","        # reset conv initialization to default uniform initialization\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.in_channels\n","                stdv = 1. / math.sqrt(n)\n","                m.weight.data.uniform_(-stdv, stdv)\n","                if m.bias is not None:\n","                    m.bias.data.uniform_(-stdv, stdv)\n","            elif isinstance(m, nn.Linear):\n","                stdv = 1. / math.sqrt(m.weight.size(1))\n","                m.weight.data.uniform_(-stdv, stdv)\n","                if m.bias is not None:\n","                    m.bias.data.uniform_(-stdv, stdv)"],"metadata":{"id":"M3OHSkpbTncT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -q vit_pytorch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BdnXxERYT1uC","executionInfo":{"status":"ok","timestamp":1714653593542,"user_tz":-120,"elapsed":111217,"user":{"displayName":"Ismael","userId":"03967480790510634870"}},"outputId":"10e6ae81-dd43-412b-9f76-5490933332d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m\u001b[0m \u001b[32m117.6/117.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["from vit_pytorch import ViT, MAE, SimpleViT\n","\n","contrastive = FeatureGetter(backbone='resnet50')\n","\n","v = SimpleViT(\n","        image_size = (16,32),\n","        patch_size = (4, 8),\n","        num_classes = 13,\n","        dim = 1024,\n","        depth = 6,\n","        heads = 8,\n","        mlp_dim = 2048,\n","        channels = 512\n","    )\n","generative = MAE(\n","        encoder = v,\n","        masking_ratio = 0.75,   # the paper recommended 75% masked patches\n","        decoder_dim = 512,      # paper showed good results with just 512\n","        decoder_depth = 6       # anywhere from 1 to 8\n","    )"],"metadata":{"id":"mDmTHfUxT9Vs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = nn.Sequential(\n","        contrastive,\n","        generative\n","    )\n","\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RnQdcA0eUGeu","executionInfo":{"status":"ok","timestamp":1714653615643,"user_tz":-120,"elapsed":289,"user":{"displayName":"Ismael","userId":"03967480790510634870"}},"outputId":"17264984-9393-483b-801a-cf0e5d3f2a75"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequential(\n","  (0): FeatureGetter(\n","    (features): Sequential(\n","      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (4): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (5): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (6): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (4): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (5): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (7): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): BottleneckLast(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","    )\n","  )\n","  (1): MAE(\n","    (encoder): SimpleViT(\n","      (to_patch_embedding): Sequential(\n","        (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=4, p2=8)\n","        (1): LayerNorm((16384,), eps=1e-05, elementwise_affine=True)\n","        (2): Linear(in_features=16384, out_features=1024, bias=True)\n","        (3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (transformer): Transformer(\n","        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (layers): ModuleList(\n","          (0-5): 6 x ModuleList(\n","            (0): Attention(\n","              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (attend): Softmax(dim=-1)\n","              (to_qkv): Linear(in_features=1024, out_features=1536, bias=False)\n","              (to_out): Linear(in_features=512, out_features=1024, bias=False)\n","            )\n","            (1): FeedForward(\n","              (net): Sequential(\n","                (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","                (1): Linear(in_features=1024, out_features=2048, bias=True)\n","                (2): GELU(approximate='none')\n","                (3): Linear(in_features=2048, out_features=1024, bias=True)\n","              )\n","            )\n","          )\n","        )\n","      )\n","      (to_latent): Identity()\n","      (linear_head): Linear(in_features=1024, out_features=13, bias=True)\n","    )\n","    (to_patch): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=4, p2=8)\n","    (patch_to_emb): Sequential(\n","      (0): LayerNorm((16384,), eps=1e-05, elementwise_affine=True)\n","      (1): Linear(in_features=16384, out_features=1024, bias=True)\n","      (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (enc_to_dec): Linear(in_features=1024, out_features=512, bias=True)\n","    (decoder): Transformer(\n","      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      (layers): ModuleList(\n","        (0-5): 6 x ModuleList(\n","          (0): Attention(\n","            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attend): Softmax(dim=-1)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n","            (to_out): Sequential(\n","              (0): Linear(in_features=512, out_features=512, bias=True)\n","              (1): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): FeedForward(\n","            (net): Sequential(\n","              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","              (1): Linear(in_features=512, out_features=2048, bias=True)\n","              (2): GELU(approximate='none')\n","              (3): Dropout(p=0.0, inplace=False)\n","              (4): Linear(in_features=2048, out_features=512, bias=True)\n","              (5): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (decoder_pos_emb): Embedding(16, 512)\n","    (to_pixels): Linear(in_features=512, out_features=16384, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"code","source":["!pip install -q batchgenerators"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4VyKRSyEVjXs","executionInfo":{"status":"ok","timestamp":1715073377153,"user_tz":-120,"elapsed":15924,"user":{"displayName":"Ismael","userId":"03967480790510634870"}},"outputId":"278fdf01-7870-4b61-ef8d-4d358641df8b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m638.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["from batchgenerators.utilities.file_and_folder_operations import *\n","import random\n","\n","all_files = sorted(os.listdir('/content/drive/MyDrive/TFG/Parte2/little_images'))\n","val_files = random.sample(all_files, 150)\n","train_files = list(set(all_files) - set(val_files))\n","\n","print('todos: ',len(all_files))\n","print('val: ',len(val_files))\n","print('resta: ', len(train_files))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VvPZVUy2VkTd","executionInfo":{"status":"ok","timestamp":1715073867561,"user_tz":-120,"elapsed":262,"user":{"displayName":"Ismael","userId":"03967480790510634870"}},"outputId":"17e2e94a-04be-4e98-c2b5-3417a12b2302"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["todos:  500\n","val:  150\n","resta:  350\n"]}]},{"cell_type":"code","source":["input_files = sorted(os.listdir('/content/drive/MyDrive/TFG/Parte2/little_images'))\n","print(input_files[0])\n","print(val_files[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OLwGMrHFXLBz","executionInfo":{"status":"ok","timestamp":1715080095465,"user_tz":-120,"elapsed":7,"user":{"displayName":"Ismael","userId":"03967480790510634870"}},"outputId":"87eede2a-4986-4045-c818-bb00c70dd590"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["pre-training_0.jpg\n","pre-training_228.jpg\n"]}]},{"cell_type":"code","source":["import skimage\n","from skimage import io\n","\n","fm = io.imread('/content/drive/MyDrive/TFG/Parte2/target_data/test/y/testing_groundtruth-8066.png')\n","print(fm.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2m58oAUyrdE5","executionInfo":{"status":"ok","timestamp":1715350764566,"user_tz":-120,"elapsed":625,"user":{"displayName":"Ismael","userId":"03967480790510634870"}},"outputId":"19062845-8d07-491f-ed89-0de6e4d724db"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["(512, 1024)\n"]}]}]}