
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 7, 'patch_size': [512, 896], 'median_image_size_in_voxels': [480.0, 853.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset212_CholecSeg8kV2', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 480, 853], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 117.45803833007812, 'median': 109.0, 'min': 0.0, 'percentile_00_5': 13.0, 'percentile_99_5': 255.0, 'std': 60.065860748291016}, '1': {'max': 255.0, 'mean': 74.5312728881836, 'median': 64.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 252.0, 'std': 54.67719650268555}, '2': {'max': 255.0, 'mean': 63.4015007019043, 'median': 55.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 250.0, 'std': 47.575199127197266}}} 
 
2024-03-23 15:45:49.782449: unpacking dataset... 
2024-03-23 15:55:20.193586: unpacking done... 
2024-03-23 15:55:20.202643: do_dummy_2d_data_aug: False 
2024-03-23 15:55:20.575207: Using splits from existing split file: E:/drive/Mi unidad/TFG/V2/nnUNet_preprocessed\Dataset212_CholecSeg8kV2\splits_final.json 
2024-03-23 15:55:21.018636: The split file contains 5 splits. 
2024-03-23 15:55:21.026137: Desired fold for training: 0 
2024-03-23 15:55:21.036138: This split has 5171 training and 1293 validation cases. 
2024-03-23 15:55:27.917186: Unable to plot network architecture: 
2024-03-23 15:55:27.923687: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH 
2024-03-23 15:55:28.374100:  
2024-03-23 15:55:28.380102: Epoch 100 
2024-03-23 15:55:28.389603: Current learning rate: 0.00631 
2024-03-23 16:03:05.980352: train_loss -0.6313 
2024-03-23 16:03:06.357246: val_loss -0.6381 
2024-03-23 16:03:06.371249: Pseudo dice [0.9874, 0.9805, 0.9587, 0.9771, 0.9579, 0.9388, 0.8579, 0.6242, 0.9661, 0.9697, 0.8734, 0.9877] 
2024-03-23 16:03:06.384251: Epoch time: 457.61 s 
2024-03-23 16:03:07.978230:  
2024-03-23 16:03:07.985732: Epoch 101 
2024-03-23 16:03:07.997233: Current learning rate: 0.00628 
2024-03-23 16:09:14.028363: train_loss -0.6275 
2024-03-23 16:09:14.453635: val_loss -0.6155 
2024-03-23 16:09:14.467138: Pseudo dice [0.9872, 0.9789, 0.9342, 0.976, 0.9518, 0.9341, 0.8394, 0.9049, 0.9627, 0.9644, 0.7856, 0.9225] 
2024-03-23 16:09:14.484140: Epoch time: 366.05 s 
2024-03-23 16:09:16.078068:  
2024-03-23 16:09:16.088570: Epoch 102 
2024-03-23 16:09:16.104573: Current learning rate: 0.00624 
2024-03-23 16:15:21.814212: train_loss -0.6194 
2024-03-23 16:15:22.205781: val_loss -0.6366 
2024-03-23 16:15:22.223283: Pseudo dice [0.987, 0.978, 0.9543, 0.9762, 0.9482, 0.9439, 0.8719, 0.6236, 0.97, 0.9642, 0.8266, 0.9871] 
2024-03-23 16:15:22.238286: Epoch time: 365.74 s 
2024-03-23 16:15:23.833763:  
2024-03-23 16:15:23.841265: Epoch 103 
2024-03-23 16:15:23.851766: Current learning rate: 0.0062 
2024-03-23 16:21:30.589673: train_loss -0.6311 
2024-03-23 16:21:30.981108: val_loss -0.6272 
2024-03-23 16:21:31.007877: Pseudo dice [0.986, 0.9775, 0.9492, 0.98, 0.9541, 0.9448, 0.8684, 0.8686, 0.9685, 0.9688, 0.8214, 0.9872] 
2024-03-23 16:21:31.024381: Epoch time: 366.76 s 
2024-03-23 16:21:32.613892:  
2024-03-23 16:21:32.655897: Epoch 104 
2024-03-23 16:21:32.673399: Current learning rate: 0.00616 
2024-03-23 16:27:36.403308: train_loss -0.6259 
2024-03-23 16:27:36.817156: val_loss -0.6268 
2024-03-23 16:27:36.829158: Pseudo dice [0.9855, 0.9778, 0.9504, 0.9774, 0.9511, 0.9407, 0.87, 0.9102, 0.9673, 0.9669, 0.7839, 0.9912] 
2024-03-23 16:27:36.847117: Epoch time: 363.79 s 
2024-03-23 16:27:38.344775:  
2024-03-23 16:27:38.352277: Epoch 105 
2024-03-23 16:27:38.362778: Current learning rate: 0.00612 
2024-03-23 16:33:39.687140: train_loss -0.6157 
2024-03-23 16:33:40.043811: val_loss -0.6042 
2024-03-23 16:33:40.064314: Pseudo dice [0.9874, 0.9802, 0.952, 0.9777, 0.9528, 0.9435, 0.8882, 0.9172, 0.9633, 0.968, 0.7984, 0.9905] 
2024-03-23 16:33:40.080317: Epoch time: 361.34 s 
2024-03-23 16:33:41.985149:  
2024-03-23 16:33:41.992651: Epoch 106 
2024-03-23 16:33:42.003652: Current learning rate: 0.00609 
2024-03-23 16:39:45.591016: train_loss -0.6422 
2024-03-23 16:39:45.971582: val_loss -0.6462 
2024-03-23 16:39:45.992585: Pseudo dice [0.9869, 0.9791, 0.9508, 0.9759, 0.9548, 0.9498, 0.8529, 0.677, 0.9676, 0.9673, 0.846, 0.9867] 
2024-03-23 16:39:46.009588: Epoch time: 363.61 s 
2024-03-23 16:39:47.639873:  
2024-03-23 16:39:47.647374: Epoch 107 
2024-03-23 16:39:47.657876: Current learning rate: 0.00605 
2024-03-23 16:45:43.781749: train_loss -0.6297 
2024-03-23 16:45:44.203046: val_loss -0.6609 
2024-03-23 16:45:44.214047: Pseudo dice [0.9874, 0.978, 0.9521, 0.9774, 0.9443, 0.9372, 0.8635, 0.9063, 0.9663, 0.9614, 0.848, 0.9899] 
2024-03-23 16:45:44.225050: Epoch time: 356.14 s 
2024-03-23 16:45:45.747563:  
2024-03-23 16:45:45.756064: Epoch 108 
2024-03-23 16:45:45.769068: Current learning rate: 0.00601 
2024-03-23 16:52:21.769787: train_loss -0.6313 
2024-03-23 16:52:22.185198: val_loss -0.6339 
2024-03-23 16:52:22.197700: Pseudo dice [0.9884, 0.982, 0.9532, 0.9799, 0.9501, 0.9504, 0.9077, 0.9071, 0.9684, 0.9677, 0.8649, 0.9872] 
2024-03-23 16:52:22.209202: Epoch time: 396.02 s 
2024-03-23 16:52:22.222743: Yayy! New best EMA pseudo Dice: 0.9355 
2024-03-23 16:52:30.324443:  
2024-03-23 16:52:30.333444: Epoch 109 
2024-03-23 16:52:30.346947: Current learning rate: 0.00597 
2024-03-23 17:01:42.657262: train_loss -0.6312 
2024-03-23 17:01:43.172850: val_loss -0.6732 
2024-03-23 17:01:43.186853: Pseudo dice [0.9874, 0.98, 0.9462, 0.9781, 0.9469, 0.9409, 0.8553, 0.9156, 0.9711, 0.9645, 0.8225, 0.9895] 
2024-03-23 17:01:43.199355: Epoch time: 552.33 s 
2024-03-23 17:01:43.210357: Yayy! New best EMA pseudo Dice: 0.9361 
2024-03-23 17:01:49.961492:  
2024-03-23 17:01:49.978494: Epoch 110 
2024-03-23 17:01:49.993497: Current learning rate: 0.00593 
2024-03-23 17:09:15.855659: train_loss -0.6454 
2024-03-23 17:09:16.334955: val_loss -0.645 
2024-03-23 17:09:16.345456: Pseudo dice [0.9883, 0.9811, 0.9542, 0.9799, 0.953, 0.9419, 0.868, 0.9096, 0.97, 0.9658, 0.8307, 0.9914] 
2024-03-23 17:09:16.356958: Epoch time: 445.9 s 
2024-03-23 17:09:16.367460: Yayy! New best EMA pseudo Dice: 0.9369 
2024-03-23 17:09:23.398786:  
2024-03-23 17:09:23.408288: Epoch 111 
2024-03-23 17:09:23.421790: Current learning rate: 0.0059 
2024-03-23 17:15:36.135036: train_loss -0.6251 
2024-03-23 17:15:36.568112: val_loss -0.6502 
2024-03-23 17:15:36.583614: Pseudo dice [0.9851, 0.9784, 0.9571, 0.9768, 0.9453, 0.9416, 0.8572, 0.9221, 0.9567, 0.9616, 0.8152, 0.9848] 
2024-03-23 17:15:36.597618: Epoch time: 372.74 s 
2024-03-23 17:15:36.614620: Yayy! New best EMA pseudo Dice: 0.9372 
2024-03-23 17:15:45.274463:  
2024-03-23 17:15:45.282965: Epoch 112 
2024-03-23 17:15:45.296468: Current learning rate: 0.00586 
2024-03-23 17:21:47.558033: train_loss -0.6268 
2024-03-23 17:21:47.935821: val_loss -0.6231 
2024-03-23 17:21:47.948823: Pseudo dice [0.988, 0.9806, 0.9573, 0.9811, 0.9514, 0.9486, 0.8563, 0.9181, 0.9694, 0.9707, 0.8248, 0.988] 
2024-03-23 17:21:47.961325: Epoch time: 362.29 s 
2024-03-23 17:21:47.973828: Yayy! New best EMA pseudo Dice: 0.938 
2024-03-23 17:21:55.858426:  
2024-03-23 17:21:55.866928: Epoch 113 
2024-03-23 17:21:55.880430: Current learning rate: 0.00582 
2024-03-23 17:27:57.321895: train_loss -0.6261 
2024-03-23 17:27:57.720846: val_loss -0.6312 
2024-03-23 17:27:57.731348: Pseudo dice [0.9859, 0.9788, 0.9561, 0.9813, 0.9499, 0.9486, 0.8806, 0.9136, 0.9739, 0.9676, 0.8307, 0.9868] 
2024-03-23 17:27:57.768788: Epoch time: 361.46 s 
2024-03-23 17:27:57.797787: Yayy! New best EMA pseudo Dice: 0.9388 
2024-03-23 17:28:05.453887:  
2024-03-23 17:28:05.461388: Epoch 114 
2024-03-23 17:28:05.472389: Current learning rate: 0.00578 
2024-03-23 17:34:09.187095: train_loss -0.6277 
2024-03-23 17:34:09.198096: val_loss -0.641 
2024-03-23 17:34:09.209599: Pseudo dice [0.9869, 0.9799, 0.9559, 0.9735, 0.9526, 0.9381, 0.8602, 0.4608, 0.971, 0.9673, 0.8189, 0.9884] 
2024-03-23 17:34:09.220100: Epoch time: 363.73 s 
2024-03-23 17:34:10.779065:  
2024-03-23 17:34:10.788067: Epoch 115 
2024-03-23 17:34:10.802572: Current learning rate: 0.00574 
2024-03-23 17:40:48.770702: train_loss -0.6396 
2024-03-23 17:40:49.217587: val_loss -0.6241 
2024-03-23 17:40:49.228589: Pseudo dice [0.9871, 0.9795, 0.951, 0.9798, 0.9545, 0.9384, 0.8884, 0.815, 0.9648, 0.9636, 0.7752, 0.9887] 
2024-03-23 17:40:49.238091: Epoch time: 397.99 s 
2024-03-23 17:40:50.861254:  
2024-03-23 17:40:50.871756: Epoch 116 
2024-03-23 17:40:50.888260: Current learning rate: 0.0057 
2024-03-23 17:46:54.639694: train_loss -0.6315 
2024-03-23 17:46:55.012124: val_loss -0.6622 
2024-03-23 17:46:55.025126: Pseudo dice [0.9865, 0.9799, 0.9594, 0.9766, 0.9545, 0.9475, 0.8848, 0.6644, 0.9688, 0.9705, 0.831, 0.9909] 
2024-03-23 17:46:55.038128: Epoch time: 363.78 s 
2024-03-23 17:46:56.568048:  
2024-03-23 17:46:56.575550: Epoch 117 
2024-03-23 17:46:56.586052: Current learning rate: 0.00567 
2024-03-23 17:53:04.335509: train_loss -0.6361 
2024-03-23 17:53:04.736079: val_loss -0.6532 
2024-03-23 17:53:04.752581: Pseudo dice [0.9882, 0.981, 0.9505, 0.9808, 0.9542, 0.953, 0.8911, 0.9098, 0.9672, 0.9711, 0.8463, 0.9872] 
2024-03-23 17:53:04.764083: Epoch time: 367.77 s 
2024-03-23 17:53:06.289247:  
2024-03-23 17:53:06.297749: Epoch 118 
2024-03-23 17:53:06.310251: Current learning rate: 0.00563 
2024-03-23 17:59:21.429345: train_loss -0.643 
2024-03-23 17:59:21.803617: val_loss -0.6606 
2024-03-23 17:59:21.815118: Pseudo dice [0.9849, 0.9804, 0.9613, 0.9794, 0.9569, 0.9488, 0.8876, 0.9165, 0.9733, 0.9688, 0.8498, 0.9908] 
2024-03-23 17:59:21.828121: Epoch time: 375.14 s 
2024-03-23 17:59:23.599336:  
2024-03-23 17:59:23.606337: Epoch 119 
2024-03-23 17:59:23.617339: Current learning rate: 0.00559 
2024-03-23 18:05:53.323644: train_loss -0.6341 
2024-03-23 18:05:53.689214: val_loss -0.6319 
2024-03-23 18:05:53.715719: Pseudo dice [0.9882, 0.9811, 0.9483, 0.9794, 0.9541, 0.9504, 0.8819, 0.92, 0.9701, 0.9713, 0.7955, 0.9874] 
2024-03-23 18:05:53.730721: Epoch time: 389.73 s 
2024-03-23 18:05:55.250949:  
2024-03-23 18:05:55.260951: Epoch 120 
2024-03-23 18:05:55.275454: Current learning rate: 0.00555 
2024-03-23 18:12:01.183190: train_loss -0.6356 
2024-03-23 18:12:01.583578: val_loss -0.6782 
2024-03-23 18:12:01.593580: Pseudo dice [0.9889, 0.9818, 0.9557, 0.9802, 0.9513, 0.9462, 0.8636, 0.9135, 0.9707, 0.9692, 0.8338, 0.9897] 
2024-03-23 18:12:01.608397: Epoch time: 365.93 s 
2024-03-23 18:12:03.153180:  
2024-03-23 18:12:03.161681: Epoch 121 
2024-03-23 18:12:03.175184: Current learning rate: 0.00551 
2024-03-23 18:18:08.364606: train_loss -0.6407 
2024-03-23 18:18:08.784683: val_loss -0.6252 
2024-03-23 18:18:08.795685: Pseudo dice [0.9873, 0.9803, 0.9596, 0.9788, 0.9543, 0.9476, 0.87, 0.6655, 0.9705, 0.9718, 0.8438, 0.9878] 
2024-03-23 18:18:08.806686: Epoch time: 365.21 s 
2024-03-23 18:18:10.470477:  
2024-03-23 18:18:10.477978: Epoch 122 
2024-03-23 18:18:10.488480: Current learning rate: 0.00547 
2024-03-23 18:24:10.030846: train_loss -0.6343 
2024-03-23 18:24:10.450920: val_loss -0.645 
2024-03-23 18:24:10.467422: Pseudo dice [0.9845, 0.9768, 0.9554, 0.9779, 0.9512, 0.9474, 0.8724, 0.6082, 0.9653, 0.9672, 0.8099, 0.9891] 
2024-03-23 18:24:10.532434: Epoch time: 359.56 s 
2024-03-23 18:24:12.109640:  
2024-03-23 18:24:12.119643: Epoch 123 
2024-03-23 18:24:12.134645: Current learning rate: 0.00544 
2024-03-23 18:30:31.454424: train_loss -0.6309 
2024-03-23 18:30:31.867994: val_loss -0.637 
2024-03-23 18:30:31.881497: Pseudo dice [0.9877, 0.9773, 0.9521, 0.9802, 0.9538, 0.9438, 0.8507, 0.9123, 0.9693, 0.9695, 0.8296, 0.984] 
2024-03-23 18:30:31.893999: Epoch time: 379.35 s 
2024-03-23 18:30:33.486144:  
2024-03-23 18:30:33.493647: Epoch 124 
2024-03-23 18:30:33.504648: Current learning rate: 0.0054 
2024-03-23 18:38:05.494689: train_loss -0.6287 
2024-03-23 18:38:05.889327: val_loss -0.6609 
2024-03-23 18:38:05.909331: Pseudo dice [0.9887, 0.9813, 0.955, 0.98, 0.9565, 0.9427, 0.8779, 0.9089, 0.9732, 0.9662, 0.8111, 0.9873] 
2024-03-23 18:38:05.924334: Epoch time: 452.01 s 
2024-03-23 18:38:07.608627:  
2024-03-23 18:38:07.617128: Epoch 125 
2024-03-23 18:38:07.632631: Current learning rate: 0.00536 
2024-03-23 18:48:50.286283: train_loss -0.643 
2024-03-23 18:48:50.672350: val_loss -0.6369 
2024-03-23 18:48:50.685352: Pseudo dice [0.9877, 0.9809, 0.95, 0.979, 0.954, 0.9486, 0.8669, 0.5796, 0.97, 0.969, 0.8188, 0.9861] 
2024-03-23 18:48:50.695855: Epoch time: 642.68 s 
2024-03-23 18:48:52.361651:  
2024-03-23 18:48:52.370152: Epoch 126 
2024-03-23 18:48:52.383155: Current learning rate: 0.00532 
2024-03-23 18:57:46.028321: train_loss -0.6294 
2024-03-23 18:57:46.423429: val_loss -0.6541 
2024-03-23 18:57:46.433930: Pseudo dice [0.9883, 0.9812, 0.9562, 0.9813, 0.9531, 0.9367, 0.8636, 0.9123, 0.9718, 0.968, 0.8769, 0.9875] 
2024-03-23 18:57:46.443932: Epoch time: 533.67 s 
2024-03-23 18:57:47.913067:  
2024-03-23 18:57:47.921567: Epoch 127 
2024-03-23 18:57:47.934571: Current learning rate: 0.00528 
2024-03-23 19:04:04.124842: train_loss -0.636 
2024-03-23 19:04:04.530912: val_loss -0.6308 
2024-03-23 19:04:04.547416: Pseudo dice [0.9884, 0.9808, 0.964, 0.9805, 0.9589, 0.9462, 0.869, 0.9136, 0.9711, 0.9711, 0.8326, 0.9884] 
2024-03-23 19:04:04.581422: Epoch time: 376.21 s 
2024-03-23 19:04:06.084176:  
2024-03-23 19:04:06.091678: Epoch 128 
2024-03-23 19:04:06.102181: Current learning rate: 0.00524 
2024-03-23 19:10:17.425865: train_loss -0.6314 
2024-03-23 19:10:17.860941: val_loss -0.6241 
2024-03-23 19:10:17.877444: Pseudo dice [0.989, 0.9812, 0.9418, 0.9775, 0.9574, 0.9447, 0.8934, 0.5402, 0.9697, 0.9657, 0.8547, 0.9891] 
2024-03-23 19:10:17.890947: Epoch time: 371.34 s 
2024-03-23 19:10:19.501509:  
2024-03-23 19:10:19.509510: Epoch 129 
2024-03-23 19:10:19.521512: Current learning rate: 0.0052 
2024-03-23 19:16:23.040242: train_loss -0.6458 
2024-03-23 19:16:23.442379: val_loss -0.6664 
2024-03-23 19:16:23.453380: Pseudo dice [0.9893, 0.9823, 0.9538, 0.9802, 0.9562, 0.947, 0.8905, 0.9072, 0.9708, 0.9703, 0.8314, 0.9866] 
2024-03-23 19:16:23.463383: Epoch time: 363.54 s 
2024-03-23 19:16:24.971591:  
2024-03-23 19:16:24.980593: Epoch 130 
2024-03-23 19:16:24.995595: Current learning rate: 0.00517 
2024-03-23 19:22:33.415649: train_loss -0.6493 
2024-03-23 19:22:33.804217: val_loss -0.6487 
2024-03-23 19:22:33.816720: Pseudo dice [0.9859, 0.9824, 0.9448, 0.9764, 0.9542, 0.9493, 0.8659, 0.924, 0.9716, 0.9701, 0.7934, 0.988] 
2024-03-23 19:22:33.830222: Epoch time: 368.45 s 
2024-03-23 19:22:35.473260:  
2024-03-23 19:22:35.480762: Epoch 131 
2024-03-23 19:22:35.491263: Current learning rate: 0.00513 
2024-03-23 19:28:33.366659: train_loss -0.6374 
2024-03-23 19:28:33.758177: val_loss -0.646 
2024-03-23 19:28:33.807185: Pseudo dice [0.9878, 0.9812, 0.9571, 0.9787, 0.9534, 0.941, 0.8534, 0.701, 0.9643, 0.9675, 0.9096, 0.989] 
2024-03-23 19:28:33.856004: Epoch time: 357.89 s 
2024-03-23 19:28:35.575177:  
2024-03-23 19:28:35.582678: Epoch 132 
2024-03-23 19:28:35.595180: Current learning rate: 0.00509 
2024-03-23 19:34:31.101014: train_loss -0.6445 
2024-03-23 19:34:31.512289: val_loss -0.6371 
2024-03-23 19:34:31.525291: Pseudo dice [0.9873, 0.9825, 0.9569, 0.9771, 0.9523, 0.9369, 0.8798, 0.615, 0.9704, 0.9683, 0.8443, 0.9902] 
2024-03-23 19:34:31.537793: Epoch time: 355.53 s 
2024-03-23 19:34:33.197083:  
2024-03-23 19:34:33.204585: Epoch 133 
2024-03-23 19:34:33.215587: Current learning rate: 0.00505 
2024-03-23 19:40:31.262076: train_loss -0.6365 
2024-03-23 19:40:31.670635: val_loss -0.6336 
2024-03-23 19:40:31.687639: Pseudo dice [0.9887, 0.9816, 0.949, 0.9796, 0.9566, 0.9463, 0.8961, 0.6232, 0.9725, 0.9694, 0.829, 0.9875] 
2024-03-23 19:40:31.706141: Epoch time: 358.07 s 
2024-03-23 19:40:33.238889:  
2024-03-23 19:40:33.246890: Epoch 134 
2024-03-23 19:40:33.262392: Current learning rate: 0.00501 
2024-03-23 19:46:29.936274: train_loss -0.6419 
2024-03-23 19:46:30.326365: val_loss -0.6533 
2024-03-23 19:46:30.336366: Pseudo dice [0.9875, 0.9791, 0.948, 0.9781, 0.9526, 0.9461, 0.8785, 0.8958, 0.9708, 0.9667, 0.8184, 0.9916] 
2024-03-23 19:46:30.346368: Epoch time: 356.7 s 
2024-03-23 19:46:31.944819:  
2024-03-23 19:46:31.953320: Epoch 135 
2024-03-23 19:46:31.966823: Current learning rate: 0.00497 
2024-03-23 19:52:23.196681: train_loss -0.6311 
2024-03-23 19:52:23.593576: val_loss -0.6354 
2024-03-23 19:52:23.621378: Pseudo dice [0.9891, 0.9827, 0.9611, 0.9817, 0.9576, 0.9459, 0.874, 0.9125, 0.9716, 0.9718, 0.8382, 0.9915] 
2024-03-23 19:52:23.633380: Epoch time: 351.25 s 
2024-03-23 19:52:25.166952:  
2024-03-23 19:52:25.175455: Epoch 136 
2024-03-23 19:52:25.188457: Current learning rate: 0.00493 
2024-03-23 19:58:11.205436: train_loss -0.6431 
2024-03-23 19:58:11.602505: val_loss -0.6616 
2024-03-23 19:58:11.615006: Pseudo dice [0.9884, 0.9813, 0.9537, 0.9797, 0.9568, 0.9472, 0.8829, 0.9241, 0.9717, 0.9674, 0.8299, 0.9877] 
2024-03-23 19:58:11.627508: Epoch time: 346.04 s 
2024-03-23 19:58:13.293342:  
2024-03-23 19:58:13.300843: Epoch 137 
2024-03-23 19:58:13.310845: Current learning rate: 0.00489 
2024-03-23 20:04:12.994279: train_loss -0.6308 
2024-03-23 20:04:13.358115: val_loss -0.6659 
2024-03-23 20:04:13.378089: Pseudo dice [0.9889, 0.9822, 0.9492, 0.9786, 0.9531, 0.9543, 0.8868, 0.925, 0.97, 0.9697, 0.8082, 0.9903] 
2024-03-23 20:04:13.392098: Epoch time: 359.7 s 
2024-03-23 20:04:15.260527:  
2024-03-23 20:04:15.272068: Epoch 138 
2024-03-23 20:04:15.286572: Current learning rate: 0.00485 
2024-03-23 20:10:37.614345: train_loss -0.6428 
2024-03-23 20:10:38.004122: val_loss -0.6615 
2024-03-23 20:10:38.018624: Pseudo dice [0.9882, 0.9803, 0.9503, 0.9814, 0.9585, 0.9484, 0.887, 0.9233, 0.973, 0.9688, 0.8276, 0.9897] 
2024-03-23 20:10:38.030626: Epoch time: 382.35 s 
2024-03-23 20:10:38.051630: Yayy! New best EMA pseudo Dice: 0.9391 
2024-03-23 20:10:45.296744:  
2024-03-23 20:10:45.306247: Epoch 139 
2024-03-23 20:10:45.319748: Current learning rate: 0.00482 
2024-03-23 20:17:23.132629: train_loss -0.6502 
2024-03-23 20:17:23.540604: val_loss -0.6604 
2024-03-23 20:17:23.551605: Pseudo dice [0.9887, 0.9828, 0.9547, 0.9811, 0.957, 0.9444, 0.8752, 0.9166, 0.9724, 0.9703, 0.8266, 0.9874] 
2024-03-23 20:17:23.561107: Epoch time: 397.84 s 
2024-03-23 20:17:23.571109: Yayy! New best EMA pseudo Dice: 0.9398 
2024-03-23 20:17:30.165215:  
2024-03-23 20:17:30.172717: Epoch 140 
2024-03-23 20:17:30.183719: Current learning rate: 0.00478 
2024-03-23 20:24:46.722914: train_loss -0.6408 
2024-03-23 20:24:47.183775: val_loss -0.6765 
2024-03-23 20:24:47.195776: Pseudo dice [0.988, 0.9824, 0.9469, 0.9804, 0.9589, 0.95, 0.8871, 0.9135, 0.9709, 0.968, 0.859, 0.9889] 
2024-03-23 20:24:47.213540: Epoch time: 436.56 s 
2024-03-23 20:24:47.226043: Yayy! New best EMA pseudo Dice: 0.9408 
2024-03-23 20:24:54.519566:  
2024-03-23 20:24:54.528067: Epoch 141 
2024-03-23 20:24:54.540570: Current learning rate: 0.00474 
2024-03-23 20:30:51.789334: train_loss -0.6404 
2024-03-23 20:30:52.167255: val_loss -0.6963 
2024-03-23 20:30:52.187417: Pseudo dice [0.9894, 0.9824, 0.9581, 0.9797, 0.9557, 0.9423, 0.862, 0.9216, 0.9702, 0.9691, 0.8072, 0.987] 
2024-03-23 20:30:52.200920: Epoch time: 357.27 s 
2024-03-23 20:30:52.216925: Yayy! New best EMA pseudo Dice: 0.9411 
2024-03-23 20:31:00.154611:  
2024-03-23 20:31:00.164613: Epoch 142 
2024-03-23 20:31:00.180115: Current learning rate: 0.0047 
2024-03-23 20:36:51.859648: train_loss -0.6384 
2024-03-23 20:36:52.248937: val_loss -0.6576 
2024-03-23 20:36:52.259438: Pseudo dice [0.989, 0.9816, 0.9514, 0.9824, 0.9565, 0.9492, 0.8792, 0.9226, 0.9717, 0.9672, 0.8211, 0.9889] 
2024-03-23 20:36:52.269940: Epoch time: 351.71 s 
2024-03-23 20:36:52.285025: Yayy! New best EMA pseudo Dice: 0.9417 
2024-03-23 20:36:59.270289:  
2024-03-23 20:36:59.278790: Epoch 143 
2024-03-23 20:36:59.293793: Current learning rate: 0.00466 
2024-03-23 20:42:48.298944: train_loss -0.6416 
2024-03-23 20:42:48.724253: val_loss -0.6505 
2024-03-23 20:42:48.737257: Pseudo dice [0.9893, 0.9836, 0.9544, 0.9807, 0.9579, 0.9569, 0.9011, 0.9206, 0.9724, 0.9725, 0.8566, 0.9899] 
2024-03-23 20:42:48.750760: Epoch time: 349.03 s 
2024-03-23 20:42:48.800754: Yayy! New best EMA pseudo Dice: 0.9428 
2024-03-23 20:42:56.727864:  
2024-03-23 20:42:56.735366: Epoch 144 
2024-03-23 20:42:56.746367: Current learning rate: 0.00462 
2024-03-23 20:48:53.913570: train_loss -0.6376 
2024-03-23 20:48:54.313164: val_loss -0.6678 
2024-03-23 20:48:54.327167: Pseudo dice [0.9885, 0.9816, 0.9509, 0.9796, 0.9549, 0.9512, 0.8789, 0.9217, 0.9663, 0.9708, 0.7715, 0.9866] 
2024-03-23 20:48:54.341169: Epoch time: 357.19 s 
2024-03-23 20:48:56.046966:  
2024-03-23 20:48:56.055969: Epoch 145 
2024-03-23 20:48:56.068470: Current learning rate: 0.00458 
2024-03-23 20:54:50.794924: train_loss -0.6481 
2024-03-23 20:54:51.175123: val_loss -0.6285 
2024-03-23 20:54:51.190126: Pseudo dice [0.9882, 0.9807, 0.9409, 0.9791, 0.9589, 0.9452, 0.875, 0.8974, 0.9716, 0.9648, 0.8282, 0.992] 
2024-03-23 20:54:51.212130: Epoch time: 354.75 s 
2024-03-23 20:54:52.723025:  
2024-03-23 20:54:52.732527: Epoch 146 
2024-03-23 20:54:52.746529: Current learning rate: 0.00454 
2024-03-23 21:00:49.294413: train_loss -0.6263 
2024-03-23 21:00:49.705722: val_loss -0.6339 
2024-03-23 21:00:49.715723: Pseudo dice [0.9841, 0.9768, 0.9388, 0.9769, 0.9553, 0.9257, 0.8643, 0.9138, 0.9689, 0.9653, 0.8304, 0.989] 
2024-03-23 21:00:49.725725: Epoch time: 356.57 s 
2024-03-23 21:00:51.258080:  
2024-03-23 21:00:51.266081: Epoch 147 
2024-03-23 21:00:51.279583: Current learning rate: 0.0045 
2024-03-23 21:06:54.551875: train_loss -0.6255 
2024-03-23 21:06:54.944499: val_loss -0.6104 
2024-03-23 21:06:54.958001: Pseudo dice [0.988, 0.9811, 0.9516, 0.9786, 0.9484, 0.9415, 0.8628, 0.8836, 0.9676, 0.9683, 0.8157, 0.9889] 
2024-03-23 21:06:54.971504: Epoch time: 363.3 s 
2024-03-23 21:06:56.580784:  
2024-03-23 21:06:56.590786: Epoch 148 
2024-03-23 21:06:56.606288: Current learning rate: 0.00446 
2024-03-23 21:14:00.307583: train_loss -0.6293 
2024-03-23 21:14:00.894104: val_loss -0.6576 
2024-03-23 21:14:00.912609: Pseudo dice [0.9858, 0.9795, 0.9537, 0.9784, 0.9545, 0.9432, 0.8697, 0.9134, 0.9656, 0.9673, 0.8429, 0.987] 
2024-03-23 21:14:00.933112: Epoch time: 423.73 s 
2024-03-23 21:14:02.632408:  
2024-03-23 21:14:02.640409: Epoch 149 
2024-03-23 21:14:02.653412: Current learning rate: 0.00442 
2024-03-23 21:21:20.190533: train_loss -0.6334 
2024-03-23 21:21:20.583616: val_loss -0.655 
2024-03-23 21:21:20.609614: Pseudo dice [0.9879, 0.9816, 0.9532, 0.98, 0.953, 0.9495, 0.8745, 0.9106, 0.9636, 0.9662, 0.8326, 0.9886] 
2024-03-23 21:21:20.621115: Epoch time: 437.56 s 
2024-03-23 21:21:26.832048: Yayy! New best EMA pseudo Dice: 0.9428 
2024-03-23 21:21:34.265175:  
2024-03-23 21:21:34.273675: Epoch 150 
2024-03-23 21:21:34.286677: Current learning rate: 0.00438 
2024-03-23 21:27:37.667893: train_loss -0.6219 
2024-03-23 21:27:37.676395: val_loss -0.6704 
2024-03-23 21:27:37.692437: Pseudo dice [0.9875, 0.9816, 0.9501, 0.9785, 0.955, 0.9511, 0.8818, 0.9027, 0.9659, 0.9714, 0.8412, 0.9911] 
2024-03-23 21:27:37.703440: Epoch time: 363.4 s 
2024-03-23 21:27:37.715941: Yayy! New best EMA pseudo Dice: 0.9432 
2024-03-23 21:27:39.883805:  
2024-03-23 21:27:39.892306: Epoch 151 
2024-03-23 21:27:39.903308: Current learning rate: 0.00434 
2024-03-23 21:33:39.827845: train_loss -0.634 
2024-03-23 21:33:40.239916: val_loss -0.6399 
2024-03-23 21:33:40.252918: Pseudo dice [0.9867, 0.9812, 0.9543, 0.98, 0.9571, 0.9483, 0.8888, 0.9124, 0.9665, 0.9692, 0.8153, 0.9892] 
2024-03-23 21:33:40.266421: Epoch time: 359.95 s 
2024-03-23 21:33:40.281924: Yayy! New best EMA pseudo Dice: 0.9434 
2024-03-23 21:33:48.465110:  
2024-03-23 21:33:48.474112: Epoch 152 
2024-03-23 21:33:48.487614: Current learning rate: 0.0043 
2024-03-23 21:41:15.008115: train_loss -0.6371 
2024-03-23 21:41:15.810255: val_loss -0.6691 
2024-03-23 21:41:15.827257: Pseudo dice [0.9888, 0.9815, 0.9549, 0.9803, 0.9566, 0.9447, 0.8956, 0.9119, 0.9732, 0.9667, 0.864, 0.99] 
2024-03-23 21:41:15.842760: Epoch time: 446.54 s 
2024-03-23 21:41:15.855763: Yayy! New best EMA pseudo Dice: 0.9442 
2024-03-23 21:41:23.633758:  
2024-03-23 21:41:23.651495: Epoch 153 
2024-03-23 21:41:23.673006: Current learning rate: 0.00427 
2024-03-23 21:49:39.597585: train_loss -0.634 
2024-03-23 21:49:39.998501: val_loss -0.6592 
2024-03-23 21:49:40.012504: Pseudo dice [0.9891, 0.9823, 0.9644, 0.9809, 0.9562, 0.9525, 0.8822, 0.9129, 0.9711, 0.9749, 0.8611, 0.9887] 
2024-03-23 21:49:40.025506: Epoch time: 495.96 s 
2024-03-23 21:49:40.039009: Yayy! New best EMA pseudo Dice: 0.9449 
2024-03-23 21:49:47.107178:  
2024-03-23 21:49:47.115679: Epoch 154 
2024-03-23 21:49:47.128682: Current learning rate: 0.00423 
2024-03-23 21:56:04.769884: train_loss -0.6459 
2024-03-23 21:56:05.154476: val_loss -0.6637 
2024-03-23 21:56:05.165478: Pseudo dice [0.9874, 0.9799, 0.948, 0.9803, 0.9548, 0.9535, 0.886, 0.9082, 0.9641, 0.9665, 0.8672, 0.9905] 
2024-03-23 21:56:05.175980: Epoch time: 377.66 s 
2024-03-23 21:56:05.192144: Yayy! New best EMA pseudo Dice: 0.9453 
2024-03-23 21:56:13.328043:  
2024-03-23 21:56:13.336544: Epoch 155 
2024-03-23 21:56:13.349046: Current learning rate: 0.00419 
2024-03-23 22:02:00.797980: train_loss -0.6377 
2024-03-23 22:02:01.209667: val_loss -0.6242 
2024-03-23 22:02:01.230172: Pseudo dice [0.9882, 0.9807, 0.9462, 0.9793, 0.9538, 0.9396, 0.8201, 0.9029, 0.9642, 0.9709, 0.759, 0.9895] 
2024-03-23 22:02:01.243674: Epoch time: 347.47 s 
2024-03-23 22:02:03.039861:  
2024-03-23 22:02:03.049362: Epoch 156 
2024-03-23 22:02:03.094371: Current learning rate: 0.00415 
